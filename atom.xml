<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>似水年华--沉浮</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://idber.github.io/"/>
  <updated>2020-09-28T04:44:09.746Z</updated>
  <id>http://idber.github.io/</id>
  
  <author>
    <name>Michael Guo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Gh-Ost 在线DDL变更工具​</title>
    <link href="http://idber.github.io/2020/09/27-gh-ost%20%E5%9C%A8%E7%BA%BFDDL%E5%8F%98%E6%9B%B4%E5%B7%A5%E5%85%B7%E2%80%8B.html"/>
    <id>http://idber.github.io/2020/09/27-gh-ost 在线DDL变更工具​.html</id>
    <published>2020-09-27T07:01:56.000Z</published>
    <updated>2020-09-28T04:44:09.746Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;  我们知道，MySQL 5.7以前的DLL采用的是：&lt;br&gt;新建临时表–&amp;gt;修改临时表结构–&amp;gt;然后导入数据–&amp;gt;drop原表–&amp;gt;重命名临时表为原表&lt;br&gt;MySQL 8.0仅支持加字段秒级完成，其他变更如添加索引，修改字段等仍是上述方式。比较经典的通用方案是Percona 公司开源的pt-osc 工具解决导致锁表的操作，还有一款github基于go语言开发的gh-ost。gh-ost拥有众多特性，比如 轻量级，可暂停, 可动态控制, 可审计, 可测试, 等等 ，我们可以通过操作特定的文件对正在执行的gh-ost命令进行动态调整 。&lt;br&gt;开源地址：&lt;br&gt;&lt;a href=&quot;https://github.com/github/gh-ost&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/github/gh-ost
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;说明：&lt;br&gt;本文使用的gh-ost版本：v1.1.0&lt;/p&gt;
&lt;h2 id=&quot;gh-ost-介绍&quot;&gt;&lt;a href=&quot;#gh-ost-介绍&quot; class=&quot;headerlink&quot; title=&quot;gh-ost 介绍&quot;&gt;&lt;/a&gt;gh-ost 介绍&lt;/h2&gt;&lt;p&gt;gh-ost 作为一个伪装的备库，可以从主库 / 备库上拉取 binlog，过滤之后重新应用到主库上去，相当于主库上的增量操作通过 binlog 又应用回主库本身，不过是应用在幽灵表上。&lt;/p&gt;
&lt;p&gt;其大致的工作过程:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1 gh-ost 首先连接到主库上，根据 alter 语句创建幽灵表，&lt;/p&gt;
&lt;p&gt;2 然后作为一个备库连接到其中一个真正的备库或者主库上 (根据具体的参数来定)，一边在主库上拷贝已有的数据到幽灵表，一边从备库上拉取增量数据的 binlog，然后不断的把 binlog 应用回主库。&lt;/p&gt;
&lt;p&gt;3 等待全部数据同步完成，进行 cut-over 幽灵表和原表切换。图中 cut-over 是最后一步，锁住主库的源表，等待 binlog 应用完毕，然后替换 gh-ost 表为源表。gh-ost 在执行中，会在原本的 binlog event 里面增加以下 hint 和心跳包，用来控制整个流程的进度，检测状态等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然 gh-ost 也会做很多前置的校验检查，比如 binlog_format ，表的主键和唯一键，是否有外键等等&lt;/p&gt;
&lt;p&gt;这种架构带来诸多好处，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整个流程异步执行，对于源表的增量数据操作没有额外的开销，高峰期变更业务对性能影响小。&lt;/li&gt;
&lt;li&gt;降低写压力，触发器操作都在一个事务内，gh-ost 应用 binlog 是另外一个连接在做。&lt;/li&gt;
&lt;li&gt;可停止，binlog 有位点记录，如果变更过程发现主库性能受影响，可以立刻停止拉binlog，停止应用 binlog，稳定之后继续应用。&lt;/li&gt;
&lt;li&gt;可测试，gh-ost 提供了测试功能，可以连接到一个备库上直接做 Online DDL，在备库上观察变更结果是否正确，再对主库操作，心里更有底。&lt;/li&gt;
&lt;li&gt;并行操作，对于 gh-ost 来说就是多个对主库的连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;gh-ost-操作模式&quot;&gt;&lt;a href=&quot;#gh-ost-操作模式&quot; class=&quot;headerlink&quot; title=&quot;gh-ost 操作模式&quot;&gt;&lt;/a&gt;gh-ost 操作模式&lt;/h2&gt;&lt;p&gt;a. 连接到从库，在主库做迁移这是 gh-ost 默认的工作方式。gh-ost 将会检查从库状态，找到集群结构中的主库并连接，接下来进行迁移操作:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行数据在主库上读写&lt;/li&gt;
&lt;li&gt;读取从库的二进制日志，将变更应用到主库&lt;/li&gt;
&lt;li&gt;在从库收集表格式，字段&amp;amp;索引，行数等信息&lt;/li&gt;
&lt;li&gt;在从库上读取内部的变更事件（如心跳事件）&lt;/li&gt;
&lt;li&gt;在主库切换表&lt;br&gt;如果你的主库的日志格式是 SBR，工具也可以正常工作。但从库必须启用二级制日志 ( log_bin, log_slave_updates) 并且设置 binlog_format=ROW 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;b. 连接到主库&lt;/p&gt;
&lt;p&gt;直接连接到主库构造 slave，在主库上进行 copy 数据和应用 binlog，通过指定 –allow-on-master 参数即可。当然主库的 binlog 模式必须是 row 模式。&lt;/p&gt;
&lt;p&gt;c. 在从库迁移 / 测试该模式会在从库执行迁移操作。gh-ost 会简单的连接到主库，此后所有的操作都在从库执行，不会对主库进行任何的改动。整个操作过程中，gh-ost 将控制速度保证从库可以及时的进行数据同步&lt;/p&gt;
&lt;p&gt;–migrate-on-replica 表示 gh-ost 会直接在从库上进行迁移操作。即使在复制运行阶段也可以进行表的切换操作。&lt;/p&gt;
&lt;p&gt;–test-on-replica 表示 迁移操作只是为了测试在切换之前复制会停止，然后会进行切换操作，然后在切换回来，你的原始表最终还是原始表。两个表都会保存下来，复制操作是停止的。你可以对这两个表进行一致性检查等测试操作。&lt;/p&gt;
&lt;h1 id=&quot;参数说明&quot;&gt;&lt;a href=&quot;#参数说明&quot; class=&quot;headerlink&quot; title=&quot;参数说明&quot;&gt;&lt;/a&gt;参数说明&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;-allow-master-master: 是否允许gh-ost运行在双主复制架构中，一般与-assume-master-host参数一起使用
-allow-nullable-unique-key: 允许gh-ost在数据迁移依赖的唯一键可以为NULL，默认为不允许为NULL的唯一键。如果数据迁移(migrate)依赖的唯一键允许NULL值，则可能造成数据不正确，请谨慎使用。
-allow-on-master: 允许gh-ost直接运行在主库上。默认gh-ost连接的从库。
-alter string:DDL语句
-assume-master-host string:为gh-ost指定一个主库，格式为”ip:port”或者”hostname:port”。在这主主架构里比较有用，或则在gh-ost发现不到主的时候有用。
-assume-rbr:确认gh-ost连接的数据库实例的binlog_format=ROW的情况下，可以指定-assume-rbr，这样可以禁止从库上运行stop slave,start slave,执行gh-ost用户也不需要SUPER权限。
-chunk-size int:在每次迭代中处理的行数量(允许范围：100-100000)，默认值为1000。
-concurrent-rowcount:该参数如果为True(默认值)，则进行row-copy之后，估算统计行数(使用explain select count(*)方式)，并调整ETA时间，否则，gh-ost首先预估统计行数，然后开始row-copy。
-conf string:gh-ost的配置文件路径。
-critical-load string:一系列逗号分隔的status-name=values组成，当MySQL中status超过对应的values，gh-ost将会退出。-critical-load Threads_connected=20,Connections=1500，指的是当MySQL中的状态值Threads_connected&amp;gt;20,Connections&amp;gt;1500的时候，gh-ost将会由于该数据库严重负载而停止并退出。
-critical-load-hibernate-seconds int :负载达到critical-load时，gh-ost在指定的时间内进入休眠状态。 它不会读/写任何来自任何服务器的任何内容。
-critical-load-interval-millis int:当值为0时，当达到-critical-load，gh-ost立即退出。当值不为0时，当达到-critical-load，gh-ost会在-critical-load-interval-millis秒数后，再次进行检查，再次检查依旧达到-critical-load，gh-ost将会退出。
-cut-over string:选择cut-over类型:atomic/two-step，atomic(默认)类型的cut-over是github的算法，two-step采用的是facebook-OSC的算法。
-cut-over-exponential-backoff
-cut-over-lock-timeout-seconds int:gh-ost在cut-over阶段最大的锁等待时间，当锁超时时，gh-ost的cut-over将重试。(默认值：3)
-database string:数据库名称。
-default-retries int:各种操作在panick前重试次数。(默认为60)
-dml-batch-size int:在单个事务中应用DML事件的批量大小（范围1-100）（默认值为10）
-exact-rowcount:准确统计表行数(使用select count(*)的方式)，得到更准确的预估时间。
-execute:实际执行alter&amp;amp;migrate表，默认为noop，不执行，仅仅做测试并退出，如果想要ALTER TABLE语句真正落实到数据库中去，需要明确指定-execute
-exponential-backoff-max-interval int
-force-named-cut-over:如果为true，则&amp;apos;unpostpone | cut-over&amp;apos;交互式命令必须命名迁移的表
-heartbeat-interval-millis int:gh-ost心跳频率值，默认为500
-initially-drop-ghost-table:gh-ost操作之前，检查并删除已经存在的ghost表。该参数不建议使用，请手动处理原来存在的ghost表。默认不启用该参数，gh-ost直接退出操作。
-initially-drop-old-table:gh-ost操作之前，检查并删除已经存在的旧表。该参数不建议使用，请手动处理原来存在的ghost表。默认不启用该参数，gh-ost直接退出操作。
-initially-drop-socket-file:gh-ost强制删除已经存在的socket文件。该参数不建议使用，可能会删除一个正在运行的gh-ost程序，导致DDL失败。
-max-lag-millis int:主从复制最大延迟时间，当主从复制延迟时间超过该值后，gh-ost将采取节流(throttle)措施，默认值：1500s。
-max-load string:逗号分隔状态名称=阈值，如：&amp;apos;Threads_running=30,Threads_connected=500&amp;apos;. 表面如果在执行gh-ost的过程中出现Threads_running=30则暂停gh-ost的执行, Threads_running即活跃连接数    -migrate-on-replica:gh-ost的数据迁移(migrate)运行在从库上，而不是主库上。 
-nice-ratio float:每次chunk时间段的休眠时间，范围[0.0…100.0]。0：每个chunk时间段不休眠，即一个chunk接着一个chunk执行；1：每row-copy 1毫秒，则另外休眠1毫秒；0.7：每row-copy 10毫秒，则另外休眠7毫秒。
-ok-to-drop-table: gh-ost操作结束后，删除旧表，默认状态是不删除旧表，会存在_tablename_del表。
-panic-flag-file string:当这个文件被创建，gh-ost将会立即退出。
-password string :MySQL密码
-port int ：MySQL端口，最好用从库
-postpone-cut-over-flag-file string：当这个文件存在的时候，gh-ost的cut-over阶段将会被推迟，数据仍然在复制，直到该文件被删除。
-skip-foreign-key-checks:确定你的表上没有外键时，设置为&amp;apos;true&amp;apos;，并且希望跳过gh-ost验证的时间-skip-renamed-columns ALTER
-switch-to-rbr:让gh-ost自动将从库的binlog_format转换为ROW格式。
-table string:表名
-throttle-additional-flag-file string:当该文件被创建后，gh-ost操作立即停止。该参数可以用在多个gh-ost同时操作的时候，创建一个文件，让所有的gh-ost操作停止，或者删除这个文件，让所有的gh-ost操作恢复。
-throttle-control-replicas string:列出所有需要被检查主从复制延迟的从库。
-throttle-flag-file string:当该文件被创建后，gh-ost操作立即停止。该参数适合控制单个gh-ost操作。-throttle-additional-flag-file string适合控制多个gh-ost操作。
-throttle-query string:节流查询。每秒钟执行一次。当返回值=0时不需要节流，当返回值&amp;gt;0时，需要执行节流操作。该查询会在数据迁移(migrated)服务器上操作，所以请确保该查询是轻量级的。
-timestamp-old-table:在旧表名中使用时间戳。这会使旧表名称具有唯一且无冲突的交叉迁移。
-user string :MYSQL用户
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;使用&quot;&gt;&lt;a href=&quot;#使用&quot; class=&quot;headerlink&quot; title=&quot;使用&quot;&gt;&lt;/a&gt;使用&lt;/h1&gt;&lt;h2 id=&quot;下载安装&quot;&gt;&lt;a href=&quot;#下载安装&quot; class=&quot;headerlink&quot; title=&quot;下载安装&quot;&gt;&lt;/a&gt;下载安装&lt;/h2&gt;&lt;p&gt;在github release页面下载&lt;br&gt;&lt;a href=&quot;https://github.com/github/gh-ost/releases/download/v1.1.0/gh-ost-1.1.0-1.x86_64.rpm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/github/gh-ost/releases/download/v1.1.0/gh-ost-1.1.0-1.x86_64.rpm
&lt;/a&gt;&lt;br&gt;上传到服务器,安装&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install gh-ost-1.1.0-1.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;执行变更&quot;&gt;&lt;a href=&quot;#执行变更&quot; class=&quot;headerlink&quot; title=&quot;执行变更&quot;&gt;&lt;/a&gt;执行变更&lt;/h2&gt;&lt;p&gt;示例：&lt;br&gt;自建MySQL&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gh-ost  --user=&amp;quot;xxxx&amp;quot; --password=&amp;quot;xxxx&amp;quot; --host=localhost  --database=&amp;quot;guo_test&amp;quot; --table=&amp;quot;a&amp;quot;  --alter=&amp;quot;ADD COLUMN bcbde INT&amp;quot;  --execute --max-load=Threads_running=30 --critical-load=Threads_running=50 --critical-load-interval-millis=5000 --chunk-size=1000 --heartbeat-interval-millis=2000 --ok-to-drop-table --assume-rbr --allow-on-master 2&amp;gt;&amp;amp;1 | tee  /tmp/rebuild_t1.log 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;阿里云RDS&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gh-ost  --user=&amp;quot;xxxx&amp;quot; --password=&amp;quot;xxxx&amp;quot; --aliyun-rds --host=&amp;apos;xxxx&amp;apos; --port=3306 --assume-master-host=&amp;quot;xxxx:3306&amp;quot;  --database=&amp;quot;guo_test&amp;quot; --table=&amp;quot;sbtest&amp;quot;  --alter=&amp;quot;add COLUMN aa int &amp;quot; --execute  --max-load=Threads_running=30 --critical-load=Threads_running=50 --critical-load-interval-millis=5000 --chunk-size=1000 --heartbeat-interval-millis=2000 --ok-to-drop-table --throttle-additional-flag-file=/tmp/gh-ost.throttle --panic-flag-file=/tmp/ghost.panic.flag --assume-rbr --allow-on-master --aliyun-rds  --execute 2&amp;gt;&amp;amp;1 | tee  /tmp/rebuild_t1.log 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;推荐使用参数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--assume-rbr
--max-load=Threads_running=30
--critical-load=Threads_running=50
--critical-load-interval-millis=5000
--chunk-size=1000
--heartbeat-interval-millis=2000
--throttle-additional-flag-file=/tmp/gh-ost.throttle
--panic-flag-file=/tmp/ghost.panic.flag
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;测试限流可以使用,也可以通过删除/tmp/ghost.postpone.flag文件控制cut-over时机&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--postpone-cut-over-flag-file=/tmp/ghost.postpone.flag
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面参数具体数值，根据服务器实际压力情况修改&lt;br&gt;阿里云RDS需添加如下参数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;–allow-on-master
–assume-rbr
–assume-master-host
–aliyun-rds
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;特别说明:&lt;br&gt;针对几百G的大表做归档删除数据之后要重建表，以便减少表空间大小。重建完，进行cut-over切换幽灵表和原表时，默认不删除幽灵表。因为直接删除上百 G 会对磁盘 IO 有一定的影响.&lt;/p&gt;
&lt;p&gt;根据自己的情况去调整合适的参数，注意以下两个参数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--ok-to-drop-table:gh-ost操作结束后，删除旧表，默认状态是不删除旧表，会存在_tablename_del表。
--timestamp-old-table 最终rename的时候表名会加上时间戳后缀，每次执行的时候都会生成一个新的表名。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;错误忽略&quot;&gt;&lt;a href=&quot;#错误忽略&quot; class=&quot;headerlink&quot; title=&quot;错误忽略&quot;&gt;&lt;/a&gt;错误忽略&lt;/h2&gt;&lt;p&gt;执行过程中会报一个error，日志如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copy: 1/1 100.0%; Applied: 0; Backlog: 0/1000; Time: 3s(total), 1s(copy); streamer: binlog.000003:118844; Lag: 0.01s, State: migrating; ETA: due
[2020/09/27 16:49:00] [info] binlogsyncer.go:164 syncer is closing...
[2020/09/27 16:49:01] [error] binlogstreamer.go:77 close sync with err: sync is been closing...
[2020/09/27 16:49:01] [info] binlogsyncer.go:179 syncer is closed
# Done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;[error] binlogstreamer.go:77 close sync with err: sync is been closing…&lt;br&gt;对应issue：&lt;br&gt;&lt;a href=&quot;https://github.com/github/gh-ost/issues/749&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/github/gh-ost/issues/749&lt;/a&gt;&lt;br&gt;开发者shlomi-noach的回复是&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sorry for the late response. Yes, this has been reported multiple times; this is an error message from an underlying library that connects to MySQL; however, there is no gh-ost error here, as gh-ost retries connection/operation as needed. It is unfortunate that the log contains all these messages but I can’t control it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大意为：&lt;br&gt;这是来自连接到MySQL的基础库的错误消息；没有gh-ost错误，目前无法控制&lt;/p&gt;
&lt;h2 id=&quot;暂停-恢复&quot;&gt;&lt;a href=&quot;#暂停-恢复&quot; class=&quot;headerlink&quot; title=&quot;暂停 / 恢复&quot;&gt;&lt;/a&gt;暂停 / 恢复&lt;/h2&gt;&lt;p&gt;我们可以通过创建 / 删除 throttle-additional-flag-file 指定的文件 /tmp/gh-ost.throttle 控制 gh-ost 对 binlog 应用.&lt;/p&gt;
&lt;h2 id=&quot;限流&quot;&gt;&lt;a href=&quot;#限流&quot; class=&quot;headerlink&quot; title=&quot;限流&quot;&gt;&lt;/a&gt;限流&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/github/gh-ost/blob/master/doc/throttle.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;gh-ost 可以通过 unix socket 文件或者 TCP 端口（可配置）的方式来监听请求，DBA 可以在命令运行后更改相应的参数，参考下面的例子：&lt;/p&gt;
&lt;h3 id=&quot;打开限流&quot;&gt;&lt;a href=&quot;#打开限流&quot; class=&quot;headerlink&quot; title=&quot;打开限流&quot;&gt;&lt;/a&gt;打开限流&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;echo throttle | nc -U /tmp/gh-ost.guo_test.sbtest.sock
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果没有nc，需要先安装nc，gh-ost.guo_test.sbtest.sock格式为，gh-ost.db_name.table_name.sock。&lt;/p&gt;
&lt;p&gt;_tablename_ghc 中会多一条记录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;287    2020-09-27 11:18:54    throttle at 1601263134871924413    commanded by user
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;关闭限流&quot;&gt;&lt;a href=&quot;#关闭限流&quot; class=&quot;headerlink&quot; title=&quot;关闭限流&quot;&gt;&lt;/a&gt;关闭限流&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;no-throttle | socat - /tmp/gh-ost.test.b.sock
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;_tablename_ghc 中会多一条记录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;348    2020-09-27 11:22:06    throttle at 1601263326077186389    done throttling
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改变执行参数: chunk-size=1024, max-lag-millis=100, echo max-load=”Threads_running=30” critical-load=”Threads_running=50” 这些参数都可以在运行时动态调整。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo chunk-size=1024 | nc -U  /tmp/gh-ost.guo_test.sbtest.sock
echo max-lag-millis=100 | nc -U  /tmp/gh-ost.guo_test.sbtest.sock
echo max-load=&amp;quot;Threads_running=30&amp;quot; | nc -U  /tmp/gh-ost.guo_test.sbtest.sock
echo critical-load=&amp;quot;Threads_running=50&amp;quot; | nc -U  /tmp/gh-ost.guo_test.sbtest.sock
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;终止运行&quot;&gt;&lt;a href=&quot;#终止运行&quot; class=&quot;headerlink&quot; title=&quot;终止运行&quot;&gt;&lt;/a&gt;终止运行&lt;/h3&gt;&lt;p&gt;我们通过来过创建 panic-flag-file 指定的文件，立即终止正在执行的 gh-ostmin&lt;/p&gt;
&lt;p&gt;创建文件 /tmp/ghost.panic.flag&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;touch /tmp/ghost.panic.flag
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;gh-ost log 提示&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2019-08-31 22:50:52.701 FATAL Found panic-file /tmp/ghost.panic.flag. Aborting without cleanup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;四 与 pt-osc 的对比&lt;br&gt;从功能，稳定性和性能上来看，两种工具各有千秋，虽然在高并发写的情况下，gh-ost 应用 binlog 会出现性能较低不如 pt-osc 的情况。不过 gh-ost 更灵活，支持我们根据实际情况动态调整。&lt;/p&gt;
&lt;p&gt;推荐阅读：&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/zping/p/8876148.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;初试GH-OST&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000006158503&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub开源的MySQL在线更改Schema工具&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://mysql.taobao.org/monthly/2018/05/02/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MySQL · 社区动态 · Online DDL 工具 gh-ost 支持阿里云 RDS&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;  我们知道，MySQL 5.7以前的DLL采用的是：&lt;br&gt;新建临时表–&amp;gt;修改临时表结构–&amp;gt;然后导入数据–&amp;gt;d
    
    </summary>
    
      <category term="Redis" scheme="http://idber.github.io/categories/Redis/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="DDL" scheme="http://idber.github.io/tags/DDL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL源码调试方法</title>
    <link href="http://idber.github.io/2020/09/25-MySQL%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95.html"/>
    <id>http://idber.github.io/2020/09/25-MySQL源码调试方法.html</id>
    <published>2020-09-25T09:01:56.000Z</published>
    <updated>2020-09-27T02:41:33.436Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;实验如下:&lt;br&gt;下载MySQL 5.6.26的源码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://downloads.mysql.com/archives/get/p/23/file/mysql-boost-5.7.26.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装依赖&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum -y install perl perl-devel libaio libaio-devel perl-Time-HiRes perl-DBD-MySQL perl-TermReadKey.x86_64  zlib openssl sshpass bash-completion unzip make gcc gcc-c++ cmake bison-devel  ncurses-devel gdb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编译,注意增加 DEBUG 选项。（cmake的版本要求在2.8.2以上）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cmake \
-DCMAKE_INSTALL_PREFIX=/home/mysql/mysql \
-DMYSQL_DATADIR=/data \
-DSYSCONFDIR=/etc \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_READLINE=1 \
-DWITH_DEBUG=1 \
-DMYSQL_UNIX_ADDR=/data/mysql.sock \
-DMYSQL_TCP_PORT=3306 \
-DENABLED_LOCAL_INFILE=1 \
-DEXTRA_CHARSETS=all \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci

make &amp;amp;&amp;amp; make install

scripts/mysql_install_db --user=mysql --basedir=/home/mysql/mysql --datadir=/data
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;源码安装完MySQL之后,mysql用户使用Debug模式启动&lt;br&gt;mysqld –debug –console &amp;amp;&lt;/p&gt;
&lt;p&gt;然后重头戏来了&lt;/p&gt;
&lt;p&gt;先找到MySQL的PID&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[mysql@mysql ~]$ ps -ef|grep mysqld
mysql    15487     1  0 18:02 pts/0    00:00:01 ./mysqld --debug --console
mysql    15546  1587  0 18:14 pts/0    00:00:00 grep --color=auto mysqld
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这时候,tail -f /tmp/mysqld.trace&lt;br&gt;可以看到,任何在MySQL的操作,调用的函数信息都记录在这个trace文件中.&lt;/p&gt;
&lt;p&gt;找到其中任意一行,比如 PROFILING::status_change&lt;/p&gt;
&lt;p&gt;使用命令gdb调试.&lt;br&gt;gdb –pid 15487 –tui&lt;/p&gt;
&lt;p&gt;将上述函数打断点.&lt;br&gt;break PROFILING::status_change&lt;/p&gt;
&lt;p&gt;开启另外一个MySQL终端.执行查询,然后进入gdb的断点.&lt;/p&gt;
&lt;p&gt;可以看到源码,并且单步执行,打印变量.&lt;/p&gt;
&lt;p&gt;看静态的代码一般比较枯燥,用这种方式感觉比较好入门.&lt;/p&gt;
&lt;p&gt;同样的方式,也适用于Redis&lt;/p&gt;
&lt;p&gt;相关阅读：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://idber.github.io/2016/03/28-MySQL%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2.html&quot;&gt;MySQL自动化安装部署&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;实验如下:&lt;br&gt;下载MySQL 5.6.26的源码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://downloads.mysql.com/archives/get/p/23/file/mysql-boost-5.7.26.tar.gz
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://idber.github.io/categories/Redis/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="源码" scheme="http://idber.github.io/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Redis强大的备份同步工具Redis-Shake</title>
    <link href="http://idber.github.io/2020/09/25-Redis%E5%BC%BA%E5%A4%A7%E7%9A%84%E5%A4%87%E4%BB%BD%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7Redis-Shake.html"/>
    <id>http://idber.github.io/2020/09/25-Redis强大的备份同步工具Redis-Shake.html</id>
    <published>2020-09-25T02:01:56.000Z</published>
    <updated>2020-09-25T03:49:00.529Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;redis-shake是阿里云Redis&amp;amp;MongoDB团队开源的用于redis数据同步的工具。下载地址：&lt;a href=&quot;https://github.com/alibaba/RedisShake/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;基本功能&quot;&gt;&lt;a href=&quot;#基本功能&quot; class=&quot;headerlink&quot; title=&quot;基本功能&quot;&gt;&lt;/a&gt;基本功能&lt;/h1&gt;&lt;p&gt;redis-shake是我们基于redis-port基础上进行改进的一款产品。它支持解析、恢复、备份、同步四个功能。以下主要介绍同步sync。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;恢复restore：将RDB文件恢复到目的redis数据库。&lt;/li&gt;
&lt;li&gt;备份dump：将源redis的全量数据通过RDB文件备份起来。&lt;/li&gt;
&lt;li&gt;解析decode：对RDB文件进行读取，并以json格式解析存储。&lt;/li&gt;
&lt;li&gt;同步sync：支持源redis和目的redis的数据同步，支持全量和增量数据的迁移，支持从云下到阿里云云上的同步，也支持云下到云下不同环境的同步，支持单节点、主从版、集群版之间的互相同步。需要注意的是，如果源端是集群版，可以启动一个RedisShake，从不同的db结点进行拉取，同时源端不能开启move slot功能；对于目的端，如果是集群版，写入可以是1个或者多个db结点。&lt;/li&gt;
&lt;li&gt;同步rump：支持源redis和目的redis的数据同步，仅支持全量的迁移。采用scan和restore命令进行迁移，支持不同云厂商不同redis版本的迁移。&lt;/li&gt;
&lt;li&gt;指定Key恢复:filter.key.whitelist可以过滤指定前辍的key，但是只适用于&lt;code&gt;restore&lt;/code&gt;, &lt;code&gt;sync&lt;/code&gt; and &lt;code&gt;rump&lt;/code&gt;三种模式。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;基本原理&quot;&gt;&lt;a href=&quot;#基本原理&quot; class=&quot;headerlink&quot; title=&quot;基本原理&quot;&gt;&lt;/a&gt;基本原理&lt;/h1&gt;&lt;p&gt;redis-shake的基本原理就是模拟一个从节点加入源redis集群，首先进行全量拉取并回放，然后进行增量的拉取（通过psync命令）。如下图所示：&lt;br&gt;&lt;img src=&quot;https://yqfile.alicdn.com/79f799fd8a5c75a91f6290a15be26587863950f5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;  &lt;br&gt;  如果源端是集群模式，只需要启动一个redis-shake进行拉取，同时不能开启源端的move slot操作。如果目的端是集群模式，可以写入到一个结点，然后再进行slot的迁移，当然也可以多对多写入。&lt;br&gt;  目前，redis-shake到目的端采用单链路实现，对于正常情况下，这不会成为瓶颈，但对于极端情况，qps比较大的时候，此部分性能可能成为瓶颈，后续我们可能会计划对此进行优化。另外，redis-shake到目的端的数据同步采用异步的方式，读写分离在2个线程操作，降低因为网络时延带来的同步性能下降。&lt;/p&gt;
&lt;h1 id=&quot;高效性&quot;&gt;&lt;a href=&quot;#高效性&quot; class=&quot;headerlink&quot; title=&quot;高效性&quot;&gt;&lt;/a&gt;高效性&lt;/h1&gt;&lt;p&gt;   全量同步阶段并发执行，增量同步阶段异步执行，能够达到毫秒级别延迟（取决于网络延迟）。同时，我们还对大key同步进行分批拉取，优化同步性能。&lt;/p&gt;
&lt;h1 id=&quot;监控&quot;&gt;&lt;a href=&quot;#监控&quot; class=&quot;headerlink&quot; title=&quot;监控&quot;&gt;&lt;/a&gt;监控&lt;/h1&gt;&lt;p&gt;   用户可以通过我们提供的restful拉取metric来对redis-shake进行实时监控：curl 127.0.0.1:9320/metric。&lt;/p&gt;
&lt;h1 id=&quot;校验&quot;&gt;&lt;a href=&quot;#校验&quot; class=&quot;headerlink&quot; title=&quot;校验&quot;&gt;&lt;/a&gt;校验&lt;/h1&gt;&lt;p&gt;   如何校验同步的正确性？可以采用我们开源的redis-full-check，具体原理可以参考这篇博客。&lt;/p&gt;
&lt;h1 id=&quot;支持&quot;&gt;&lt;a href=&quot;#支持&quot; class=&quot;headerlink&quot; title=&quot;支持&quot;&gt;&lt;/a&gt;支持&lt;/h1&gt;&lt;p&gt;支持2.8-5.0版本的同步。&lt;br&gt;支持codis。&lt;br&gt;支持云下到云上，云上到云上，云上到云下（阿里云目前支持主从版），其他云到阿里云等链路，帮助用户灵活构建混合云场景。&lt;/p&gt;
&lt;h1 id=&quot;开发中的功能&quot;&gt;&lt;a href=&quot;#开发中的功能&quot; class=&quot;headerlink&quot; title=&quot;开发中的功能&quot;&gt;&lt;/a&gt;开发中的功能&lt;/h1&gt;&lt;p&gt;断点续传。支持断开后按offset恢复，降低因主备切换、网络抖动造成链路断开重新同步拉取全量的性能影响。&lt;/p&gt;
&lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;p&gt;多活支持的支持，需要依赖内核的能力，目前单单依赖通道层面无法解决该问题。redis内核层面需要提供gtid的概念，以及CRDT的解决冲突的方式才可以。&lt;/p&gt;
&lt;h1 id=&quot;参数解释：&quot;&gt;&lt;a href=&quot;#参数解释：&quot; class=&quot;headerlink&quot; title=&quot;参数解释：&quot;&gt;&lt;/a&gt;参数解释：&lt;/h1&gt;&lt;p&gt;启动示例（以sync举例）：&lt;br&gt;vinllen@ ~/redis-shake/bin$ ./redis-shake -type=sync -conf=../conf/redis-shake.conf&lt;br&gt;conf路径下的redis-shake.conf存放的是配置文件，其内容及部分中文注释如下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# this is the configuration of redis-shake.
# if you have any problem, please visit https://github.com/alibaba/RedisShake/wiki/FAQ

# current configuration version, do not modify.
# 当前配置文件的版本号，请不要修改该值。
conf.version = 1

# ------------------------------------------------------
# id
id = redis-shake

# log file，日志文件，不配置将打印到stdout (e.g. /var/log/redis-shake.log )
log.file =
# log level: &amp;quot;none&amp;quot;, &amp;quot;error&amp;quot;, &amp;quot;warn&amp;quot;, &amp;quot;info&amp;quot;, &amp;quot;debug&amp;quot;. default is &amp;quot;info&amp;quot;.
log.level = info
# pid path，进程文件存储地址（e.g. /var/run/)，不配置将默认输出到执行下面,
# 注意这个是目录，真正的pid是`{pid_path}/{id}.pid`
pid_path = 

# pprof port.
system_profile = 9310
# restful port, set -1 means disable, in `restore` mode RedisShake will exit once finish restoring RDB only if this value
# is -1, otherwise, it&amp;apos;ll wait forever.
# restful port，查看metric端口, -1表示不启用，如果是`restore`模式，只有设置为-1才会在完成RDB恢复后退出，否则会一直block。
http_profile = 9320

# parallel routines number used in RDB file syncing. default is 64.
# 启动多少个并发线程同步一个RDB文件。
parallel = 32

# source redis configuration.
# used in `dump`, `sync` and `rump`.
# source redis type, e.g. &amp;quot;standalone&amp;quot; (default), &amp;quot;sentinel&amp;quot; or &amp;quot;cluster&amp;quot;.
#   1. &amp;quot;standalone&amp;quot;: standalone db mode.
#   2. &amp;quot;sentinel&amp;quot;: the redis address is read from sentinel.
#   3. &amp;quot;cluster&amp;quot;: the source redis has several db.
#   4. &amp;quot;proxy&amp;quot;: the proxy address, currently, only used in &amp;quot;rump&amp;quot; mode.
# 源端redis的类型，支持standalone，sentinel，cluster和proxy四种模式，注意：目前proxy只用于rump模式。
source.type = standalone
# ip:port
# the source address can be the following:
#   1. single db address. for &amp;quot;standalone&amp;quot; type.
#   2. ${sentinel_master_name}:${master or slave}@sentinel single/cluster address, e.g., mymaster:master@127.0.0.1:26379;127.0.0.1:26380, or @127.0.0.1:26379;127.0.0.1:26380. for &amp;quot;sentinel&amp;quot; type.
#   3. cluster that has several db nodes split by semicolon(;). for &amp;quot;cluster&amp;quot; type. e.g., 10.1.1.1:20331;10.1.1.2:20441.
#   4. proxy address(used in &amp;quot;rump&amp;quot; mode only). for &amp;quot;proxy&amp;quot; type.
# 源redis地址。对于sentinel或者开源cluster模式，输入格式为&amp;quot;master名字:拉取角色为master或者slave@sentinel的地址&amp;quot;，别的cluster
# 架构，比如codis, twemproxy, aliyun proxy等需要配置所有master或者slave的db地址。
source.address = 127.0.0.1:20441
# password of db/proxy. even if type is sentinel.
source.password_raw = 123456
# auth type, don&amp;apos;t modify it
source.auth_type = auth
# tls enable, true or false. Currently, only support standalone.
# open source redis does NOT support tls so far, but some cloud versions do.
source.tls_enable = false
# input RDB file.
# used in `decode` and `restore`.
# if the input is list split by semicolon(;), redis-shake will restore the list one by one.
# 如果是decode或者restore，这个参数表示读取的rdb文件。支持输入列表，例如：rdb.0;rdb.1;rdb.2
# redis-shake将会挨个进行恢复。
source.rdb.input = local
# the concurrence of RDB syncing, default is len(source.address) or len(source.rdb.input).
# used in `dump`, `sync` and `restore`. 0 means default.
# This is useless when source.type isn&amp;apos;t cluster or only input is only one RDB.
# 拉取的并发度，如果是`dump`或者`sync`，默认是source.address中db的个数，`restore`模式默认len(source.rdb.input)。
# 假如db节点/输入的rdb有5个，但rdb.parallel=3，那么一次只会
# 并发拉取3个db的全量数据，直到某个db的rdb拉取完毕并进入增量，才会拉取第4个db节点的rdb，
# 以此类推，最后会有len(source.address)或者len(rdb.input)个增量线程同时存在。
source.rdb.parallel = 0
# for special cloud vendor: ucloud
# used in `decode` and `restore`.
# ucloud集群版的rdb文件添加了slot前缀，进行特判剥离: ucloud_cluster。
source.rdb.special_cloud = 

# target redis configuration. used in `restore`, `sync` and `rump`.
# the type of target redis can be &amp;quot;standalone&amp;quot;, &amp;quot;proxy&amp;quot; or &amp;quot;cluster&amp;quot;.
#   1. &amp;quot;standalone&amp;quot;: standalone db mode.
#   2. &amp;quot;sentinel&amp;quot;: the redis address is read from sentinel.
#   3. &amp;quot;cluster&amp;quot;: open source cluster (not supported currently).
#   4. &amp;quot;proxy&amp;quot;: proxy layer ahead redis. Data will be inserted in a round-robin way if more than 1 proxy given.
# 目的redis的类型，支持standalone，sentinel，cluster和proxy四种模式。
target.type = standalone
# ip:port
# the target address can be the following:
#   1. single db address. for &amp;quot;standalone&amp;quot; type.
#   2. ${sentinel_master_name}:${master or slave}@sentinel single/cluster address, e.g., mymaster:master@127.0.0.1:26379;127.0.0.1:26380, or @127.0.0.1:26379;127.0.0.1:26380. for &amp;quot;sentinel&amp;quot; type.
#   3. cluster that has several db nodes split by semicolon(;). for &amp;quot;cluster&amp;quot; type.
#   4. proxy address. for &amp;quot;proxy&amp;quot; type.
target.address = 127.0.0.1:20551
# password of db/proxy. even if type is sentinel.
target.password_raw =
# auth type, don&amp;apos;t modify it
target.auth_type = auth
# all the data will be written into this db. &amp;lt; 0 means disable.
target.db = -1
# tls enable, true or false. Currently, only support standalone.
# open source redis does NOT support tls so far, but some cloud versions do.
target.tls_enable = false
# output RDB file prefix.
# used in `decode` and `dump`.
# 如果是decode或者dump，这个参数表示输出的rdb前缀，比如输入有3个db，那么dump分别是:
# ${output_rdb}.0, ${output_rdb}.1, ${output_rdb}.2
target.rdb.output = local_dump
# some redis proxy like twemproxy doesn&amp;apos;t support to fetch version, so please set it here.
# e.g., target.version = 4.0
target.version =

# use for expire key, set the time gap when source and target timestamp are not the same.
# 用于处理过期的键值，当迁移两端不一致的时候，目的端需要加上这个值
fake_time =

# how to solve when destination restore has the same key.
# rewrite: overwrite. 
# none: panic directly.
# ignore: skip this key. not used in rump mode.
# used in `restore`, `sync` and `rump`.
# 当源目的有重复key，是否进行覆写
# rewrite表示源端覆盖目的端。
# none表示一旦发生进程直接退出。
# ignore表示保留目的端key，忽略源端的同步key。该值在rump模式下没有用。
key_exists = none

# filter db, key, slot, lua.
# filter db.
# used in `restore`, `sync` and `rump`.
# e.g., &amp;quot;0;5;10&amp;quot; means match db0, db5 and db10.
# at most one of `filter.db.whitelist` and `filter.db.blacklist` parameters can be given.
# if the filter.db.whitelist is not empty, the given db list will be passed while others filtered.
# if the filter.db.blacklist is not empty, the given db list will be filtered while others passed.
# all dbs will be passed if no condition given.
# 指定的db被通过，比如0;5;10将会使db0, db5, db10通过, 其他的被过滤
filter.db.whitelist =
# 指定的db被过滤，比如0;5;10将会使db0, db5, db10过滤，其他的被通过
filter.db.blacklist =
# filter key with prefix string. multiple keys are separated by &amp;apos;;&amp;apos;.
# e.g., &amp;quot;abc;bzz&amp;quot; match let &amp;quot;abc&amp;quot;, &amp;quot;abc1&amp;quot;, &amp;quot;abcxxx&amp;quot;, &amp;quot;bzz&amp;quot; and &amp;quot;bzzwww&amp;quot;.
# used in `restore`, `sync` and `rump`.
# at most one of `filter.key.whitelist` and `filter.key.blacklist` parameters can be given.
# if the filter.key.whitelist is not empty, the given keys will be passed while others filtered.
# if the filter.key.blacklist is not empty, the given keys will be filtered while others passed.
# all the namespace will be passed if no condition given.
# 支持按前缀过滤key，只让指定前缀的key通过，分号分隔。比如指定abc，将会通过abc, abc1, abcxxx
filter.key.whitelist =
# 支持按前缀过滤key，不让指定前缀的key通过，分号分隔。比如指定abc，将会阻塞abc, abc1, abcxxx
filter.key.blacklist =
# filter given slot, multiple slots are separated by &amp;apos;;&amp;apos;.
# e.g., 1;2;3
# used in `sync`.
# 指定过滤slot，只让指定的slot通过
filter.slot =
# filter lua script. true means not pass. However, in redis 5.0, the lua 
# converts to transaction(multi+{commands}+exec) which will be passed.
# 控制不让lua脚本通过，true表示不通过
filter.lua = false

# big key threshold, the default is 500 * 1024 * 1024 bytes. If the value is bigger than
# this given value, all the field will be spilt and write into the target in order. If
# the target Redis type is Codis, this should be set to 1, please checkout FAQ to find 
# the reason.
# 正常key如果不大，那么都是直接调用restore写入到目的端，如果key对应的value字节超过了给定
# 的值，那么会分批依次一个一个写入。如果目的端是Codis，这个需要置为1，具体原因请查看FAQ。
# 如果目的端大版本小于源端，也建议设置为1。
big_key_threshold = 524288000

# enable metric
# used in `sync`.
# 是否启用metric
metric = true
# print in log
# 是否将metric打印到log中
metric.print_log = false

# sender information.
# sender flush buffer size of byte.
# used in `sync`.
# 发送缓存的字节长度，超过这个阈值将会强行刷缓存发送
sender.size = 104857600
# sender flush buffer size of oplog number.
# used in `sync`. flush sender buffer when bigger than this threshold.
# 发送缓存的报文个数，超过这个阈值将会强行刷缓存发送，对于目的端是cluster的情况，这个值
# 的调大将会占用部分内存。
sender.count = 4095
# delay channel size. once one oplog is sent to target redis, the oplog id and timestamp will also
# stored in this delay queue. this timestamp will be used to calculate the time delay when receiving
# ack from target redis.
# used in `sync`.
# 用于metric统计时延的队列
sender.delay_channel_size = 65535

# enable keep_alive option in TCP when connecting redis.
# the unit is second.
# 0 means disable.
# TCP keep-alive保活参数，单位秒，0表示不启用。
keep_alive = 0

# used in `rump`.
# number of keys captured each time. default is 100.
# 每次scan的个数，不配置则默认100.
scan.key_number = 50
# used in `rump`.
# we support some special redis types that don&amp;apos;t use default `scan` command like alibaba cloud and tencent cloud.
# 有些版本具有特殊的格式，与普通的scan命令有所不同，我们进行了特殊的适配。目前支持腾讯云的集群版&amp;quot;tencent_cluster&amp;quot;
# 和阿里云的集群版&amp;quot;aliyun_cluster&amp;quot;，注释主从版不需要配置，只针对集群版。
scan.special_cloud =
# used in `rump`.
# we support to fetching data from given file which marks the key list.
# 有些云版本，既不支持sync/psync，也不支持scan，我们支持从文件中进行读取所有key列表并进行抓取：一行一个key。
scan.key_file =

# limit the rate of transmission. Only used in `rump` currently.
# e.g., qps = 1000 means pass 1000 keys per second. default is 500,000(0 means default)
qps = 200000

# enable resume from break point, please visit xxx to see more details.
# 断点续传开关
resume_from_break_point = false

# ----------------splitter----------------
# below variables are useless for current open source version so don&amp;apos;t set.

# replace hash tag.
# used in `sync`.
replace_hash_tag = false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开源地址&lt;br&gt;redis-shake: &lt;a href=&quot;https://github.com/aliyun/redis-shake&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/aliyun/redis-shake&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;redis-shake是阿里云Redis&amp;amp;MongoDB团队开源的用于redis数据同步的工具。下载地址：&lt;a href=&quot;https://github.com/alibaba/RedisShake/releases&quot; targe
    
    </summary>
    
      <category term="Redis" scheme="http://idber.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://idber.github.io/tags/Redis/"/>
    
      <category term="备份，Key过滤" scheme="http://idber.github.io/tags/%E5%A4%87%E4%BB%BD%EF%BC%8CKey%E8%BF%87%E6%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>关于Percona XtraBackup的redo-Only参数</title>
    <link href="http://idber.github.io/2020/04/07-%E5%85%B3%E4%BA%8EPercona%20XtraBackup%E7%9A%84redo-only%E5%8F%82%E6%95%B0.html"/>
    <id>http://idber.github.io/2020/04/07-关于Percona XtraBackup的redo-only参数.html</id>
    <published>2020-04-07T02:01:56.000Z</published>
    <updated>2020-04-09T03:44:19.538Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;我们知道，在Percona XtraBackup执行增量恢复的时候有一步是加参数redo-only，如果不加这个参数，后面的增量是无法合并的。关于这个参数的作用，Percona XtraBackup官方文档的说明如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;--redo-only
This option should be used when preparing the base full backup and when merging all incrementals except the last one. It is passed directly to xtrabackup’s xtrabackup --apply-log-only option. This forces xtrabackup to skip the “rollback” phase and do a “redo” only. This is necessary if the backup will have incremental changes applied to it later. See the xtrabackup documentation for details.
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The xtrabackup –prepare step for incremental backups is not the same as for normal backups. In normal backups, two types of operations are performed to make the database consistent: committed transactions are replayed from the log file against the data files, and uncommitted transactions are rolled back. You must skip the rollback of uncommitted transactions when preparing a backup, because transactions that were uncommitted at the time of your backup may be in progress, and it’s likely that they will be committed in the next incremental backup. You should use thextrabackup –apply-log-only option to prevent the roll back phase.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Warning: Ifyoudonotusethextrabackup –apply-log-onlyoptiontopreventtherollbackphase,then your incremental backups will be useless. After transactions have been rolled back, further incremental backups cannot be applied.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大致意思是，redo-only除最后一次增量备份外，前面的增量备份在合并的时候都需要加上这个参数，即只进行前滚，不回滚，在备份进行时有事务未提交，很可能在下次增量备份的时候提交。如果执行了回滚，后面的备份将无法使用。&lt;/p&gt;
&lt;p&gt;我们知道，redo是物理日志，记录数据库页的改变，全备事务未提交，redo只写了一半的事务数据，假使是个大事务，需要写多个数据页，前M个数据页已写完，事务还没提交，增备的时候写完后面N个数据页，这样完整的事务是M+N的数据页，由于前M个数据页LSN未更新，增备的时候是不会备份这M个数据页的，如果应用undo，这样全备的M个数据页就会被回滚丢失，完整的事务就不是M+N个数据页了，只有增备的N个数据页，这样就丢失了M个数据页的数据。  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;我们知道，在Percona XtraBackup执行增量恢复的时候有一步是加参数redo-only，如果不加这个参数，后面的增量是无法合并的。关于这个参数的作用，Percona XtraBackup官方文档的说明如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="备份" scheme="http://idber.github.io/tags/%E5%A4%87%E4%BB%BD/"/>
    
      <category term="PXB" scheme="http://idber.github.io/tags/PXB/"/>
    
  </entry>
  
  <entry>
    <title>goInception的审核规则</title>
    <link href="http://idber.github.io/2020/04/01-goInception%E7%9A%84%E5%AE%A1%E6%A0%B8%E8%A7%84%E5%88%99.html"/>
    <id>http://idber.github.io/2020/04/01-goInception的审核规则.html</id>
    <published>2020-04-01T02:01:56.000Z</published>
    <updated>2020-04-01T02:45:17.404Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;引用自goInception作者文档，有时打开比较慢，放到自己博客加速&lt;br&gt;&lt;a href=&quot;https://hanchuanchuan.github.io/goInception/options.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;via&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;支持参数&quot;&gt;&lt;a href=&quot;#支持参数&quot; class=&quot;headerlink&quot; title=&quot;支持参数&quot;&gt;&lt;/a&gt;支持参数&lt;/h3&gt;&lt;p&gt;goInception的审核规则可以通过&lt;figure class=&quot;highlight plain&quot;&gt;&lt;figcaption&gt;&lt;span&gt;show variables;```查看&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;```sql&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;inception show variables;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;支持以下方式设置:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.通过&lt;figure class=&quot;highlight plain&quot;&gt;&lt;figcaption&gt;&lt;span&gt;set ```设置&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;```sql&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;inception set check_dml_limit = true;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;2.配置config.toml,并通过&lt;code&gt;-config=config.toml&lt;/code&gt;指定配置文件启动&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;./images/variables.png&quot; alt=&quot;variables列表&quot;&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数&lt;/th&gt;
&lt;th&gt;默认值&lt;/th&gt;
&lt;th&gt;可选范围&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;check_autoincrement_datatype&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;当建表时自增列的类型不为int或者bigint时报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_autoincrement_init_value&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;当建表时自增列的值指定的不为1，则报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_autoincrement_name&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;建表时，如果指定的自增列的名字不为ID，则报错，说明是有意义的，给提示&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_column_comment&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;建表时，列没有注释时报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_column_default_value&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查在建表、修改列、新增列时，新的列属性是不是要有默认值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_column_position_change &lt;code&gt;v0.9&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查列位置/顺序变更&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_column_type_change &lt;code&gt;v0.7.3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查字段类型变更&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_dml_limit&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;在DML语句中使用了LIMIT时，是不是要报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_dml_orderby&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;在DML语句中使用了Order By时，是不是要报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_dml_where&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;在DML语句中没有WHERE条件时，是不是要报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_float_double &lt;code&gt;v1.0.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;开启时,当使用 &lt;code&gt;float/double&lt;/code&gt; 类型时提示转成 &lt;code&gt;decimal&lt;/code&gt; 类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_identifier&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查标识符是否正确,规则是[a-z,A-Z,0-9,_]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_identifier_upper  &lt;code&gt;v1.0.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;要求标识符即表名、列名、索引名等必须为大写,默认为&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_implicit_type_conversion &lt;code&gt;v1.1.3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查where条件中是否存在隐式类型转换,默认值&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_index_prefix&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是不是要检查索引名字前缀为”idx_”，检查唯一索引前缀是不是”uniq_”&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_insert_field&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是不是要检查插入语句中的列链表的存在性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_primary_key&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;建表时，如果没有主键，则报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_table_comment&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;建表时，表没有注释时报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_timestamp_count &lt;code&gt;v0.6.0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;配置是否检查current_timestamp数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_timestamp_default&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;建表时，如果没有为timestamp类型指定默认值，则报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default_charset &lt;code&gt;v1.0.5&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;‘utf8mb4’&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;设置连接数据库的默认字符集,默认值为&lt;code&gt;utf8mb4&lt;/code&gt; (解决低版本不支持utf8mb4的问题)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_autoincrement_unsigned&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;自增列是不是要为无符号型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_blob_not_null &lt;code&gt;v1.0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许blob/text/json类型置为&lt;code&gt;not null&lt;/code&gt;,默认为&lt;code&gt;false&lt;/code&gt;,即不允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_blob_type&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查是不是支持BLOB字段，包括建表、修改列、新增列操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_change_column &lt;code&gt;v1.0.3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;设置是否支持change column语法,默认值&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_column_charset&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;允许列自己设置字符集&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_drop_database&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许删除数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_drop_table&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许删除表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_enum_set_bit&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是不是支持enum,set,bit数据类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_fingerprint &lt;code&gt;v0.6.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;sql指纹功能。dml语句相似时，可以根据相同的指纹ID复用explain结果，以减少远端数据库explain操作，并提高审核速度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;explain_rule &lt;code&gt;v1.1.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;“first”&lt;/td&gt;
&lt;td&gt;“first”, “max”&lt;/td&gt;
&lt;td&gt;explain判断受影响行数时使用的规则(&lt;code&gt;&amp;quot;first&amp;quot;, &amp;quot;max&amp;quot;&lt;/code&gt;)。  &lt;code&gt;&amp;quot;first&amp;quot;&lt;/code&gt;: 使用第一行的explain结果作为受影响行数, &lt;code&gt;&amp;quot;max&amp;quot;&lt;/code&gt;:         使用explain结果中的最大值作为受影响行数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_foreign_key&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是不是支持外键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_identifer_keyword&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;检查在SQL语句中，是不是有标识符被写成MySQL的关键字，默认值为报警。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_json_type  &lt;code&gt;v0.7.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;设置是否允许json类型字段，包括建表、修改列、新增列操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_minimal_rollback &lt;code&gt;v1.1.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;设置是否启用最小化回滚SQL，当开启时，update的回滚语句仅记录最小化变更(未变更列不再记录), 默认为&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_not_innodb  &lt;code&gt;v1.0-rc4 已删除&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;&lt;code&gt;已删除!&lt;/code&gt; 请使用 &lt;code&gt;enable_set_engine&lt;/code&gt;和 &lt;code&gt;support_engine&lt;/code&gt;以便于更灵活的指定存储引擎。 &lt;em&gt;建表指定的存储引擎不为Innodb，不报错&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_nullable&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;创建或者新增列时是否允许列为NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_null_index_name &lt;code&gt;v0.7.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;创建索引时是否允许空索引名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_orderby_rand&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;order by rand时是不是报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_partition_table&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是不是支持分区表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_pk_columns_only_int&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否强制主键列必须是int&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_select_star&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;Select*时是不是要报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_set_charset&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许指定表和数据库的字符集&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_set_collation &lt;code&gt;v0.7&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许指定表和数据库的排序规则&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_set_engine  &lt;code&gt;v1.0-rc4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否允许指定存储引擎,默认为&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_sql_statistic &lt;code&gt;v0.9&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;开启统计功能. 详见 &lt;strong&gt;&lt;a href=&quot;../statistics&quot;&gt;统计功能&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_timestamp_type &lt;code&gt;v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;设置是否允许 &lt;code&gt;timestamp&lt;/code&gt; 类型字段，包括建表、修改列、新增列操作，默认为 &lt;code&gt;true&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;enable_zero_date &lt;code&gt;v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;设置是否支持时间为0值，关闭时强制报错。默认值为 &lt;code&gt;true&lt;/code&gt;，即开启，此时会基于数据库sql_mode的NO_ZERO_DATE判断是否支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;general_log &lt;code&gt;v0.8.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;是否记录全量日志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hex_blob &lt;code&gt;v1.1.4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;在解析binlog时,二进制类型如果无法以字符串形式保存,则以十六进制字符串转储(影响类型:binary,varbinary,blob),默认关闭&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;lang &lt;code&gt;v0.5.1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;en-US&lt;/td&gt;
&lt;td&gt;en-US,zh-CN&lt;/td&gt;
&lt;td&gt;返回的信息使用语言,可选值&lt;code&gt;en-US&lt;/code&gt;,&lt;code&gt;zh-CN&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_allowed_packet    &lt;code&gt;v1.0-rc3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;4194304&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;允许的最大数据包大小.默认为 &lt;code&gt;4194304&lt;/code&gt;,单位字节,即4MB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_char_length&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;最大char长度,当超出时警告转换为varchar类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_ddl_affect_rows &lt;code&gt;v1.0.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;当DDL预估受影响行数超出设置值时警告,为0时不限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_insert_rows   &lt;code&gt;v0.6.3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;设置insert values允许的最大行数.0为不限制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_key_parts&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;一个索引最多可指定的列数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_keys&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;单表允许的最大索引数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_primary_key_parts&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;主键最多可指定的列数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_update_rows&lt;/td&gt;
&lt;td&gt;5000&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;当update/delete预估受影响行数超出设置值时警告&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;merge_alter_table&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true,false&lt;/td&gt;
&lt;td&gt;在多个改同一个表的语句出现是，报错，提示合成一个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;must_have_columns  &lt;code&gt;v0.6.3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;‘’&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;用以指定建表时必须创建的列。多个列时以逗号分隔(&lt;code&gt;格式: 列名 [列类型,可选]&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;skip_sqls &lt;code&gt;v1.0-rc3&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;‘’&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;指定不再审核的SQL.该参数指定要跳过的客户端/框架默认SQL,以实现客户端兼容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sql_safe_updates&lt;/td&gt;
&lt;td&gt;-1&lt;/td&gt;
&lt;td&gt;-1,0,1&lt;/td&gt;
&lt;td&gt;安全更新.-1表示不做操作,基于远端数据库,0表示关闭安全更新,1表示开启安全更新&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;support_charset&lt;/td&gt;
&lt;td&gt;utf8,utf8mb4&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;支持的字符集,多个时以逗号分隔&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;support_collation &lt;code&gt;v0.7&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;‘’&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;支持的排序规则,多个时以逗号分隔&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;support_engine &lt;code&gt;v1.0-rc4&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;‘innodb’&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;支持的存储引擎类型.默认为&lt;code&gt;innodb&lt;/code&gt;,此处可以设置多个,以逗号分隔,或者修改默认的存在引擎类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;wait_timeout &lt;code&gt;v1.1.2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;远端数据库等待超时时间, 单位:秒, 默认值为 &lt;code&gt;0&lt;/code&gt; 时表示使用数据库默认值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--
inception_read_only     设置当前Inception服务器是不是只读的，这是为了防止一些人具有修改权限的帐号时，通过Inception误修改一些数据，如果inception_read_only设置为ON，则即使开了enable-execute，同时又有执行权限，也不会去执行，审核完成即返回
 --&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;引用自goInception作者文档，有时打开比较慢，放到自己博客加速&lt;br&gt;&lt;a href=&quot;https://hanchuanchuan.github.io/goInception/options.html&quot; target=&quot;_blank&quot; rel=&quot;noope
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="审核" scheme="http://idber.github.io/tags/%E5%AE%A1%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 8 秒加字段初探</title>
    <link href="http://idber.github.io/2020/03/19-MySQL%208%20%E7%A7%92%E5%8A%A0%E5%AD%97%E6%AE%B5%E5%88%9D%E6%8E%A2.html"/>
    <id>http://idber.github.io/2020/03/19-MySQL 8 秒加字段初探.html</id>
    <published>2020-03-19T02:01:56.000Z</published>
    <updated>2020-03-19T05:46:11.735Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;前言： &lt;/p&gt;
&lt;p&gt; Mysql 8.0版本合并了腾讯互娱数据库团队的Patch，可以实现秒级添加字段，这个功能可谓是mysql数据库攻城狮的福音，解决了之前5.6，5.7版本添加字段很高的运维成本。由于添加索引需要扫描行记录，所以添加索引不支持秒加，添加字段只是元数据打个标记，所以支持秒加。&lt;/p&gt;
&lt;p&gt;限制：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;仅支持在一条语句中添加列，也就是说，如果同一条语句中还有其他非INSTANT操作，则无法立即完成
仅支持最后添加列，不支持在现有列的中间
不支持COMPRESSED行格式
不支持已经有全文索引的表
不支持DD表空间中的任何表
不支持临时表
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MySQL官方团队博客关于秒加字段的介绍：&lt;br&gt; &lt;a href=&quot;https://mysqlserverteam.com/mysql-8-0-innodb-now-supports-instant-add-column/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MySQL 8.0: InnoDB now supports Instant ADD COLUMN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下面是验证mysql8.0版本秒级添加字段的过程&lt;/p&gt;
&lt;p&gt;加字段可以秒加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE `guo_test`.`test_user` ADD COLUMN `next_id` INT (11) NULL AFTER `open_id`,ALGORITHM=INSTANT; 
Query OK, 0 rows affected (0.09 sec)
Records: 0  Duplicates: 0  Warnings: 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;加索引不支持INSTANT&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE `guo_test`.`test_user` ADD KEY `idx_next_id` (`next_id`) USING BTREE,ALGORITHM=INSTANT; 
1845 - ALGORITHM=INSTANT is not supported for this operation. Try ALGORITHM=COPY/INPLACE.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;索引只能通过COPY/INPLACE方式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE `guo_test`.`test_user` ADD KEY `idx_next_id` (`next_id`) USING BTREE;
Query OK, 0 rows affected (8.78 sec)
Records: 0  Duplicates: 0  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重建索引支持INSTANT&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE test_user DROP KEY idx_next_id,ADD KEY idx_next_id (next_id) USING BTREE,ALGORITHM=INSTANT; 
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;删除索引不支持INSTANT&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE test_user DROP COLUMN next_id ,ALGORITHM=INSTANT; 
1845 - ALGORITHM=INSTANT is not supported for this operation. Try ALGORITHM=COPY/INPLACE.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;删除索引只能通过COPY/INPLACE方式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; ALTER TABLE test_user DROP COLUMN next_id; 
Query OK, 0 rows affected (44.35 sec)
Records: 0  Duplicates: 0  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;前言： &lt;/p&gt;
&lt;p&gt; Mysql 8.0版本合并了腾讯互娱数据库团队的Patch，可以实现秒级添加字段，这个功能可谓是mysql数据库攻城狮的福音，解决了之前5.6，5.7版本添加字段很高的运维成本。由于添加索引需要扫描行记录，所以添加索引不支持秒加，添加字段
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="join" scheme="http://idber.github.io/tags/join/"/>
    
  </entry>
  
  <entry>
    <title>MySQL数据类型DECIMAL用法</title>
    <link href="http://idber.github.io/2020/01/18-MySQL%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8BDECIMAL%E7%94%A8%E6%B3%95.html"/>
    <id>http://idber.github.io/2020/01/18-MySQL数据类型DECIMAL用法.html</id>
    <published>2020-01-18T02:01:56.000Z</published>
    <updated>2020-01-18T02:56:11.417Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;前言： &lt;/p&gt;
&lt;p&gt;当我们需要存储小数，并且有精度要求，比如存储金额时，通常会考虑使用DECIMAL字段类型，可能大部分同学只是对DECIMAL类型略有了解，其中的细节还不甚清楚，本篇文章将从零开始，为你讲述DECIMAL字段类型的使用场景及方法。&lt;/p&gt;
&lt;h1 id=&quot;1-DECIMAL类型简介&quot;&gt;&lt;a href=&quot;#1-DECIMAL类型简介&quot; class=&quot;headerlink&quot; title=&quot;1.DECIMAL类型简介&quot;&gt;&lt;/a&gt;1.DECIMAL类型简介&lt;/h1&gt;&lt;p&gt;DECIMAL从MySQL 5.1引入，列的声明语法是DECIMAL(M,D)。NUMERIC与DECIMAL同义，如果字段类型定义为NUMERIC，则将自动转成DECIMAL。&lt;/p&gt;
&lt;p&gt;对于声明语法DECIMAL(M,D)，自变量的值范围如下：&lt;/p&gt;
&lt;p&gt;M是最大位数（精度），范围是1到65。可不指定，默认值是10。&lt;br&gt;D是小数点右边的位数（小数位）。范围是0到30，并且不能大于M，可不指定，默认值是0。&lt;br&gt;例如字段 salary DECIMAL(5,2)，能够存储具有五位数字和两位小数的任何值，因此可以存储在salary列中的值的范围是从-999.99到999.99。&lt;/p&gt;
&lt;h2 id=&quot;2-DECIMAL使用实战&quot;&gt;&lt;a href=&quot;#2-DECIMAL使用实战&quot; class=&quot;headerlink&quot; title=&quot;2.DECIMAL使用实战&quot;&gt;&lt;/a&gt;2.DECIMAL使用实战&lt;/h2&gt;&lt;p&gt;下面我们将创建测试表来验证DECIMAL字段类型的使用：&lt;/p&gt;
&lt;h2 id=&quot;创建具有DECIMAL字段的表-验证decimal默认是decimal-10-0&quot;&gt;&lt;a href=&quot;#创建具有DECIMAL字段的表-验证decimal默认是decimal-10-0&quot; class=&quot;headerlink&quot; title=&quot;创建具有DECIMAL字段的表 验证decimal默认是decimal(10,0)&quot;&gt;&lt;/a&gt;创建具有DECIMAL字段的表 验证decimal默认是decimal(10,0)&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create table decimal_tb (col1 decimal,col2 decimal(5,2));
Query OK, 0 rows affected (0.04 sec)

mysql&amp;gt; show create table decimal_tb\G
*************************** 1. row ***************************
       Table: decimal_tb
Create Table: CREATE TABLE `decimal_tb` (
  `col1` decimal(10,0) DEFAULT NULL,
  `col2` decimal(5,2) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;插入数据测试&quot;&gt;&lt;a href=&quot;#插入数据测试&quot; class=&quot;headerlink&quot; title=&quot;插入数据测试&quot;&gt;&lt;/a&gt;插入数据测试&lt;/h2&gt;&lt;h2 id=&quot;结论：超出存储范围会报错，小数位不足会自动补0，首位数字为0自动忽略，小数位超出会截断-并按四舍五入处理。&quot;&gt;&lt;a href=&quot;#结论：超出存储范围会报错，小数位不足会自动补0，首位数字为0自动忽略，小数位超出会截断-并按四舍五入处理。&quot; class=&quot;headerlink&quot; title=&quot;结论：超出存储范围会报错，小数位不足会自动补0，首位数字为0自动忽略，小数位超出会截断 并按四舍五入处理。&quot;&gt;&lt;/a&gt;结论：超出存储范围会报错，小数位不足会自动补0，首位数字为0自动忽略，小数位超出会截断 并按四舍五入处理。&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; insert into decimal_tb (col1,col2) values (100,100);
Query OK, 1 row affected (0.05 sec)

mysql&amp;gt; insert into decimal_tb (col2) values (1.23);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into decimal_tb (col2) values (10.2);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into decimal_tb (col2) values (09.9);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; select * from decimal_tb;
+------+--------+
| col1 | col2   |
+------+--------+
|  100 | 100.00 |
| NULL |   1.23 |
| NULL |  10.20 |
| NULL |   9.90 |
+------+--------+
4 rows in set (0.00 sec)

mysql&amp;gt; insert into decimal_tb (col2) values (9999);
ERROR 1264 (22003): Out of range value for column &amp;apos;col2&amp;apos; at row 1

mysql&amp;gt; insert into decimal_tb (col2) values (12.233); 
Query OK, 1 row affected, 1 warning (0.01 sec)

mysql&amp;gt; show warnings;
+-------+------+-------------------------------------------+
| Level | Code | Message                                   |
+-------+------+-------------------------------------------+
| Note  | 1265 | Data truncated for column &amp;apos;col2&amp;apos; at row 1 |
+-------+------+-------------------------------------------+
1 row in set (0.00 sec)

mysql&amp;gt; insert into decimal_tb (col2) values (12.2300);
Query OK, 1 row affected (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;变量范围测试&quot;&gt;&lt;a href=&quot;#变量范围测试&quot; class=&quot;headerlink&quot; title=&quot;变量范围测试&quot;&gt;&lt;/a&gt;变量范围测试&lt;/h1&gt;&lt;h1 id=&quot;结论：M范围是1到65，D范围是0到30，且D不大于M&quot;&gt;&lt;a href=&quot;#结论：M范围是1到65，D范围是0到30，且D不大于M&quot; class=&quot;headerlink&quot; title=&quot;结论：M范围是1到65，D范围是0到30，且D不大于M&quot;&gt;&lt;/a&gt;结论：M范围是1到65，D范围是0到30，且D不大于M&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; alter table decimal_tb add column col3 decimal(6,6);
Query OK, 0 rows affected (0.12 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql&amp;gt; alter table decimal_tb add column col4 decimal(6,7); 
ERROR 1427 (42000): For float(M,D), double(M,D) or decimal(M,D), M must be &amp;gt;= D (column &amp;apos;col4&amp;apos;).

mysql&amp;gt; alter table decimal_tb add column col4 decimal(65,2);
Query OK, 0 rows affected (0.11 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql&amp;gt; alter table decimal_tb add column col4 decimal(66,2);
ERROR 1426 (42000): Too-big precision 66 specified for &amp;apos;col4&amp;apos;. Maximum is 65.

mysql&amp;gt; alter table decimal_tb add column col5 decimal(60,30); 
Query OK, 0 rows affected (0.13 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql&amp;gt; alter table decimal_tb add column col6 decimal(60,31);
ERROR 1425 (42000): Too big scale 31 specified for column &amp;apos;col6&amp;apos;. Maximum is 30.
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;3-DECIMAL使用总结&quot;&gt;&lt;a href=&quot;#3-DECIMAL使用总结&quot; class=&quot;headerlink&quot; title=&quot;3.DECIMAL使用总结&quot;&gt;&lt;/a&gt;3.DECIMAL使用总结&lt;/h1&gt;&lt;p&gt;上面的内容从实战出发，介绍了DECIMAL类型的使用方法及注意事项，你可能也知道float、double这些浮点数类型，这两个同样可以存储小数，但这里不过多介绍，只是提醒大家float、double类型无法确保精度，很容易产生误差，特别是在求和计算的时候，所有当存储小数，特别是涉及金额时推荐使用DECIMAL类型。这里总结下使用DECIMAL应该注意的事项：&lt;/p&gt;
&lt;p&gt;DECIMAL(M,D)中，M范围是1到65，D范围是0到30。&lt;br&gt;M默认为10，D默认为0，D不大于M。&lt;br&gt;DECIMAL(5,2)可存储范围是从-999.99到999.99，超出存储范围会报错。&lt;br&gt;存储数值时，小数位不足会自动补0，首位数字为0自动忽略。&lt;br&gt;小数位超出会截断，产生告警，并按四舍五入处理。&lt;br&gt;使用DECIMAL字段时，建议M，D参数手动指定，并按需分配。&lt;br&gt;总结： &lt;/p&gt;
&lt;p&gt;本文比较简单实用，通读下来，你大概会明白DECIMAL字段的使用场景及注意事项，其实对于常见的字段类型，我们只需要了解其使用场景及注意事项即可，当我们建表时，能够快速选出合适的字段类型才是我们的目的，比如当我们需要存储小数时，能够使用DECIMAL类型并且根据业务需要选择合适的精度，这样我们的工作将很容易开展下去。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;前言： &lt;/p&gt;
&lt;p&gt;当我们需要存储小数，并且有精度要求，比如存储金额时，通常会考虑使用DECIMAL字段类型，可能大部分同学只是对DECIMAL类型略有了解，其中的细节还不甚清楚，本篇文章将从零开始，为你讲述DECIMAL字段类型的使用场景及方法。&lt;/p&gt;
&lt;
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="join" scheme="http://idber.github.io/tags/join/"/>
    
  </entry>
  
  <entry>
    <title>Join 的算法</title>
    <link href="http://idber.github.io/2019/11/25-Join%20%E7%9A%84%E7%AE%97%E6%B3%95.html"/>
    <id>http://idber.github.io/2019/11/25-Join 的算法.html</id>
    <published>2019-11-25T02:01:56.000Z</published>
    <updated>2020-04-02T02:15:51.048Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;JOIN-语法&quot;&gt;&lt;a href=&quot;#JOIN-语法&quot; class=&quot;headerlink&quot; title=&quot;JOIN 语法&quot;&gt;&lt;/a&gt;JOIN 语法&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1;
+---+------+
| a | b    |
+---+------+
| 1 | 1    |
| 2 | 11   |
| 3 | 12   |
| 5 | 50   |
+---+------+
4 rows in set (0.01 sec)

mysql&amp;gt; 

mysql&amp;gt; select * from t2;
+---+------+
| a | b    |
+---+------+
| 2 | 2    |
+---+------+
1 rows in set (0.01 sec)

mysql&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;语法一&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1,t2 where t1.a=t2.a;
+---+------+------+------+
| a | b    | a(2) | b(2) |
+---+------+------+------+
| 2 | 11   | 2    | 2    |
+---+------+------+------+
1 rows in set (0.02 sec)

mysql&amp;gt; explain select * from t1,t2 where t1.a=t2.a;
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| id | select_type | table | type   | possible_keys | key     | key_len | ref       | rows | Extra       |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| 1  | SIMPLE      | t2    | index  | PRIMARY       | b       | 123     | NULL      | 1    | Using index |
| 1  | SIMPLE      | t1    | eq_ref | PRIMARY       | PRIMARY | 4       | test.t2.a | 1    | NULL        |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
2 rows in set (0.06 sec)

mysql&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;语法二&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1 inner join t2 on t1.a=t2.a;
+---+------+------+------+
| a | b    | a(2) | b(2) |
+---+------+------+------+
| 2 | 11   | 2    | 2    |
+---+------+------+------+
1 rows in set (0.02 sec)

mysql&amp;gt; 
mysql&amp;gt; explain select * from t1 inner join t2 on t1.a=t2.a;
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| id | select_type | table | type   | possible_keys | key     | key_len | ref       | rows | Extra       |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| 1  | SIMPLE      | t2    | index  | PRIMARY       | b       | 123     | NULL      | 1    | Using index |
| 1  | SIMPLE      | t1    | eq_ref | PRIMARY       | PRIMARY | 4       | test.t2.a | 1    | NULL        |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
2 rows in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;语法三&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1 join t2 on t1.a=t2.a;
+---+------+------+------+
| a | b    | a(2) | b(2) |
+---+------+------+------+
| 2 | 11   | 2    | 2    |
+---+------+------+------+
1 rows in set (0.04 sec)

mysql&amp;gt; explain select * from t1 join t2 on t1.a=t2.a;
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| id | select_type | table | type   | possible_keys | key     | key_len | ref       | rows | Extra       |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
| 1  | SIMPLE      | t2    | index  | PRIMARY       | b       | 123     | NULL      | 1    | Using index |
| 1  | SIMPLE      | t1    | eq_ref | PRIMARY       | PRIMARY | 4       | test.t2.a | 1    | NULL        |
+----+-------------+-------+--------+---------------+---------+---------+-----------+------+-------------+
2 rows in set (0.02 sec)

mysql&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 通过上述的EXPLAIN可以得知，三种JOIN语法在执行性能和效果上都是一样的。&lt;/p&gt;
&lt;h1 id=&quot;JOIN算法&quot;&gt;&lt;a href=&quot;#JOIN算法&quot; class=&quot;headerlink&quot; title=&quot;JOIN算法&quot;&gt;&lt;/a&gt;JOIN算法&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;nsted_loop join&lt;ol&gt;
&lt;li&gt;simple nested-loop join &lt;/li&gt;
&lt;li&gt;index nested-loop join &lt;/li&gt;
&lt;li&gt;block nested-loop join&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;simple-nested-loop-join&quot;&gt;&lt;a href=&quot;#simple-nested-loop-join&quot; class=&quot;headerlink&quot; title=&quot;simple nested loop join&quot;&gt;&lt;/a&gt;simple nested loop join&lt;/h2&gt;&lt;p&gt;simple nested_loog join算法可以理解成两个for循环，外循环走一次，内循环走N次(N=外循环的次数) 其算法伪代码如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;For each row r in R do # 扫􏰀R表 
  For each row s in S do # 扫􏰀S表
    If r and s satisfy the join condition # 如果r和s满足join条件 
      Then output the tuple # 那就输出结果集
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;R 表，该表只扫描了一次;&lt;/li&gt;
&lt;li&gt;S 表，该表扫面了 count(R) 次;&lt;/li&gt;
&lt;li&gt;该方法相当于是一个笛卡尔积，实际上数据库不会使用该算法;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;index-nested-loop-join&quot;&gt;&lt;a href=&quot;#index-nested-loop-join&quot; class=&quot;headerlink&quot; title=&quot;index nested loop join&quot;&gt;&lt;/a&gt;index nested loop join&lt;/h2&gt;&lt;p&gt;index nested_loop join算法是将外表扫􏰀一次，内表不会直接去扫描，而是查找内表相应的索引的方式，和外表的记录进行匹配&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;For each row r in R do # 扫􏰀R表
  lookup s in S index # 查询S表的索引(固定3~4次IO，B+树高度)
    if found s == r # 如果 r匹配了索引s Then output the tuple # 输出结果集
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;S表上有索引&lt;/li&gt;
&lt;li&gt;扫描R表，将R表的记录和S表中的索引进行匹配&lt;/li&gt;
&lt;li&gt;R表上可以没有索引&lt;/li&gt;
&lt;li&gt;&lt;p&gt;优化器倾向使用记录数少的表作为外表(又称驱动表)&lt;/p&gt;
&lt;p&gt;如果数据量大，index nested loop join的成本也是高的，尤其是在二级索引的情况下，需要大量的回表操作&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;block-nested-loop-join&quot;&gt;&lt;a href=&quot;#block-nested-loop-join&quot; class=&quot;headerlink&quot; title=&quot;block nested loop join&quot;&gt;&lt;/a&gt;block nested loop join&lt;/h2&gt;&lt;p&gt;block nested loop join将外表中的需要join匹配的列(不是完整的记录)暂时保存在一块内存(join buffer)中，让后将这块内存中的数据和内表进行匹配(内表只扫描一次) block nested loop join 可被用于联接的是ALL，index，range的类型&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;For each tuple r in R do
  store used columns as p from R in join buffer # 将部分或者全部R的记录保存到 join buffer中，记为p 
    For each tuple s in S do
    If p and s satisfy the join condition # p 与 s满足join条件 
      Then output the tuple # 输出为结果集
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;block nested loop join 与 simple nested loop join 相比，多了一个 join buffer&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &amp;quot;%join%buffer%&amp;quot;;
+------------------+-----------+
| Variable_name    | Value     |
+------------------+-----------+
| join_buffer_size | 134217728 |  -- 128M，默认是256K
+------------------+-----------+
1 rows in set (0.05 sec)

mysql&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;join buffer用的不是Buffer Pool中的内存，而是线程级别的内存。 可以通过explain查看执行计划，并通过 join条件字段 的大小，来预估 join_buffer_size 的大小。&lt;/p&gt;
&lt;p&gt;注意:&lt;br&gt;增大join_buffer_size 进行优化的前提是 没有使用index ，如果使用了index，根本不会使用block nested join算法&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;JOIN-语法&quot;&gt;&lt;a href=&quot;#JOIN-语法&quot; class=&quot;headerlink&quot; title=&quot;JOIN 语法&quot;&gt;&lt;/a&gt;JOIN 语法&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from t1;
+---+----
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="join" scheme="http://idber.github.io/tags/join/"/>
    
      <category term="算法" scheme="http://idber.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 各种线程状态</title>
    <link href="http://idber.github.io/2019/08/01-MySQL%20%E5%90%84%E7%A7%8D%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.html"/>
    <id>http://idber.github.io/2019/08/01-MySQL 各种线程状态.html</id>
    <published>2019-08-01T02:01:56.000Z</published>
    <updated>2019-08-01T09:09:04.621Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;以下列举了State 与常规查询处理相关联的线程值，而不是更具体的活动（如复制）。其中许多仅用于查找服务器中的错误。&lt;/p&gt;
&lt;p&gt;After create&lt;/p&gt;
&lt;p&gt;当线程在创建表的函数末尾创建表（包括内部临时表）时，会发生这种情况。即使由于某些错误而无法创建表，也会使用此状态。&lt;/p&gt;
&lt;p&gt;Analyzing&lt;/p&gt;
&lt;p&gt;线程正在计算MyISAM表键分布（例如，for ANALYZE TABLE）。&lt;/p&gt;
&lt;p&gt;checking permissions&lt;/p&gt;
&lt;p&gt;线程正在检查服务器是否具有执行语句所需的权限。&lt;/p&gt;
&lt;p&gt;Checking table&lt;/p&gt;
&lt;p&gt;该线程正在执行表检查操作。&lt;/p&gt;
&lt;p&gt;cleaning up&lt;/p&gt;
&lt;p&gt;该线程已经处理了一个命令，并准备释放内存并重置某些状态变量。&lt;/p&gt;
&lt;p&gt;closing tables&lt;/p&gt;
&lt;p&gt;该线程正在将更改的表数据刷新到磁盘并关闭已使用的表。这应该是一个快速的操作。如果不是，请验证您没有完整磁盘并且磁盘使用不是很大。&lt;/p&gt;
&lt;p&gt;converting HEAP to ondisk&lt;/p&gt;
&lt;p&gt;该线程正在将内部临时表从 MEMORY表转换为磁盘表。&lt;/p&gt;
&lt;p&gt;copy to tmp table&lt;/p&gt;
&lt;p&gt;线程正在处理一个ALTER TABLE语句。在创建具有新结构的表但在将行复制到其中之前，将发生此状态。&lt;/p&gt;
&lt;p&gt;Copying to group table&lt;/p&gt;
&lt;p&gt;如果语句具有不同的条件ORDER BY和 GROUP BY标准，则按组对行进行排序并将其复制到临时表。&lt;/p&gt;
&lt;p&gt;Copying to tmp table&lt;/p&gt;
&lt;p&gt;服务器正在复制到内存中的临时表。&lt;/p&gt;
&lt;p&gt;altering table&lt;/p&gt;
&lt;p&gt;服务器正在执行就地 ALTER TABLE。&lt;/p&gt;
&lt;p&gt;Copying to tmp table on disk&lt;/p&gt;
&lt;p&gt;服务器正在复制到磁盘上的临时表。临时结果集变得太大。因此，线程正在将临时表从内存更改为基于磁盘的格式以节省内存。&lt;/p&gt;
&lt;p&gt;Creating index&lt;/p&gt;
&lt;p&gt;线程正在处理ALTER TABLE … ENABLE KEYS一个MyISAM表。&lt;/p&gt;
&lt;p&gt;Creating sort index&lt;/p&gt;
&lt;p&gt;线程正在处理SELECT使用内部临时表解析的线程。&lt;/p&gt;
&lt;p&gt;creating table&lt;/p&gt;
&lt;p&gt;线程正在创建一个表。这包括创建临时表。&lt;/p&gt;
&lt;p&gt;Creating tmp table&lt;/p&gt;
&lt;p&gt;该线程正在内存或磁盘上创建临时表。如果表在内存中创建但稍后转换为磁盘表，则该操作期间的状态将为Copying to tmp table on disk。&lt;/p&gt;
&lt;p&gt;committing alter table to storage engine&lt;/p&gt;
&lt;p&gt;服务器已完成就地 ALTER TABLE并提交结果。&lt;/p&gt;
&lt;p&gt;deleting from main table&lt;/p&gt;
&lt;p&gt;服务器正在执行多表删除的第一部分。它仅从第一个表中删除，并保存用于从其他（引用）表中删除的列和偏移量。&lt;/p&gt;
&lt;p&gt;deleting from reference tables&lt;/p&gt;
&lt;p&gt;服务器正在执行多表删除的第二部分，并从其他表中删除匹配的行。&lt;/p&gt;
&lt;p&gt;discard_or_import_tablespace&lt;/p&gt;
&lt;p&gt;线程正在处理ALTER TABLE … DISCARD TABLESPACE或ALTER TABLE … IMPORT TABLESPACE声明。&lt;/p&gt;
&lt;p&gt;end&lt;/p&gt;
&lt;p&gt;这发生在结束，但的清理之前 ALTER TABLE， CREATE VIEW， DELETE， INSERT， SELECT，或 UPDATE语句。&lt;/p&gt;
&lt;p&gt;executing&lt;/p&gt;
&lt;p&gt;该线程已开始执行语句。&lt;/p&gt;
&lt;p&gt;Execution of init_command&lt;/p&gt;
&lt;p&gt;线程正在执行init_command系统变量值中的语句 。&lt;/p&gt;
&lt;p&gt;freeing items&lt;/p&gt;
&lt;p&gt;线程执行了一个命令。在此状态期间完成的一些项目的释放涉及查询缓存。这种状态通常紧随其后cleaning up。&lt;/p&gt;
&lt;p&gt;FULLTEXT initialization&lt;/p&gt;
&lt;p&gt;服务器正准备执行自然语言全文搜索。&lt;/p&gt;
&lt;p&gt;init&lt;/p&gt;
&lt;p&gt;出现这种情况的初始化之前 ALTER TABLE， DELETE， INSERT， SELECT，或 UPDATE语句。服务器在此状态下采取的操作包括刷新二进制日志，InnoDB日志和一些查询缓存清理操作。&lt;/p&gt;
&lt;p&gt;对于end州，可能会发生以下操作：&lt;/p&gt;
&lt;p&gt;删除表中的数据后删除查询缓存条目&lt;/p&gt;
&lt;p&gt;将事件写入二进制日志&lt;/p&gt;
&lt;p&gt;释放内存缓冲区，包括blob&lt;/p&gt;
&lt;p&gt;Killed&lt;/p&gt;
&lt;p&gt;有人KILL 向线程发送了一个语句，它应该在下次检查kill标志时中止。在MySQL的每个主循环中检查该标志，但在某些情况下，线程可能仍然需要很短的时间才能死掉。如果线程被某个其他线程锁定，则一旦另一个线程释放其锁定，kill就会生效。&lt;/p&gt;
&lt;p&gt;logging slow query&lt;/p&gt;
&lt;p&gt;该线程正在向慢查询日志写一条语句。&lt;/p&gt;
&lt;p&gt;login&lt;/p&gt;
&lt;p&gt;连接线程的初始状态，直到客户端成功通过身份验证。&lt;/p&gt;
&lt;p&gt;manage keys&lt;/p&gt;
&lt;p&gt;服务器正在启用或禁用表索引。&lt;/p&gt;
&lt;p&gt;NULL&lt;/p&gt;
&lt;p&gt;该状态用于该SHOW PROCESSLIST状态。&lt;/p&gt;
&lt;p&gt;Opening tables&lt;/p&gt;
&lt;p&gt;线程正在尝试打开一个表。这应该是非常快的程序，除非有什么东西阻止打开。例如，一个ALTER TABLE或一个 LOCK TABLE语句可以阻止在语句结束之前打开表。还值得检查您的table_open_cache价值是否足够大。&lt;/p&gt;
&lt;p&gt;optimizing&lt;/p&gt;
&lt;p&gt;服务器正在对查询执行初始优化。&lt;/p&gt;
&lt;p&gt;preparing&lt;/p&gt;
&lt;p&gt;在查询优化期间发生此状态。&lt;/p&gt;
&lt;p&gt;Purging old relay logs&lt;/p&gt;
&lt;p&gt;该线程正在删除不需要的中继日志文件。&lt;/p&gt;
&lt;p&gt;query end&lt;/p&gt;
&lt;p&gt;处理查询后但在freeing items状态之前发生此 状态。&lt;/p&gt;
&lt;p&gt;Receiving from client&lt;/p&gt;
&lt;p&gt;服务器正在从客户端读取数据包。Reading from net在MySQL 5.7.8之前调用此状态。&lt;/p&gt;
&lt;p&gt;Removing duplicates&lt;/p&gt;
&lt;p&gt;该查询使用 SELECT DISTINCT的方式是MySQL无法在早期阶段优化掉不同的操作。因此，在将结果发送到客户端之前，MySQL需要额外的阶段来删除所有重复的行。&lt;/p&gt;
&lt;p&gt;removing tmp table&lt;/p&gt;
&lt;p&gt;该线程在处理SELECT 语句后删除内部临时表。如果未创建临时表，则不使用此状态。&lt;/p&gt;
&lt;p&gt;rename&lt;/p&gt;
&lt;p&gt;该线程正在重命名一个表。&lt;/p&gt;
&lt;p&gt;rename result table&lt;/p&gt;
&lt;p&gt;线程正在处理一个ALTER TABLE语句，创建了新表，并重命名它以替换原始表。&lt;/p&gt;
&lt;p&gt;Reopen tables&lt;/p&gt;
&lt;p&gt;该线程获得了表的锁定，但在获取锁定之后注意到基础表结构发生了变化。它释放了锁，关闭了桌子，并试图重新打开它。&lt;/p&gt;
&lt;p&gt;Repair by sorting&lt;/p&gt;
&lt;p&gt;修复代码使用排序来创建索引。&lt;/p&gt;
&lt;p&gt;preparing for alter table&lt;/p&gt;
&lt;p&gt;服务器正准备执行就地 ALTER TABLE。&lt;/p&gt;
&lt;p&gt;Repair done&lt;/p&gt;
&lt;p&gt;该线程已完成对MyISAM表的多线程修复 。&lt;/p&gt;
&lt;p&gt;Repair with keycache&lt;/p&gt;
&lt;p&gt;修复代码通过密钥缓存逐个创建密钥。这比慢得多Repair by sorting。&lt;/p&gt;
&lt;p&gt;Rolling back&lt;/p&gt;
&lt;p&gt;该线程正在回滚一个事务。&lt;/p&gt;
&lt;p&gt;Saving state&lt;/p&gt;
&lt;p&gt;对于MyISAM诸如修复或分析的表操作，线程将新表状态保存到.MYI文件头。状态包括诸如行数， AUTO_INCREMENT计数器和密钥分发之类的信息。&lt;/p&gt;
&lt;p&gt;Searching rows for update&lt;/p&gt;
&lt;p&gt;该线程正在进行第一阶段以在更新之前查找所有匹配的行。如果 UPDATE要更改用于查找所涉及行的索引，则必须执行此操作。&lt;/p&gt;
&lt;p&gt;Sending data&lt;/p&gt;
&lt;p&gt;线程正在读取和处理SELECT语句的行 ，并将数据发送到客户端。由于在此状态期间发生的操作往往会执行大量磁盘访问（读取），因此它通常是给定查询生命周期中运行时间最长的状态。&lt;/p&gt;
&lt;p&gt;Sending to client&lt;/p&gt;
&lt;p&gt;服务器正在向客户端写入数据包。Writing to net在MySQL 5.7.8之前调用此状态。&lt;/p&gt;
&lt;p&gt;setup&lt;/p&gt;
&lt;p&gt;线程正在开始一个ALTER TABLE操作。&lt;/p&gt;
&lt;p&gt;Sorting for group&lt;/p&gt;
&lt;p&gt;线程正在进行排序以满足a GROUP BY。&lt;/p&gt;
&lt;p&gt;Sorting for order&lt;/p&gt;
&lt;p&gt;线程正在进行排序以满足ORDER BY。&lt;/p&gt;
&lt;p&gt;Sorting index&lt;/p&gt;
&lt;p&gt;该线程正在对索引页面进行排序，以便在MyISAM表优化操作期间进行更有效的访&lt;/p&gt;
&lt;p&gt;Sorting result&lt;/p&gt;
&lt;p&gt;正在对结果进行排序，类似Creating sort index，不过是正常表，而不是在内存表中进行排序建议：创建适当的索引&lt;/p&gt;
&lt;p&gt;statistics&lt;/p&gt;
&lt;p&gt;服务器正在计算统计信息以分配执行计划。如果线程长时间处于此状态，则服务器可能是磁盘IO性能很差建议：查看当前io性能状态，例如iowait&lt;/p&gt;
&lt;p&gt;System lock&lt;/p&gt;
&lt;p&gt;该线程已调用mysql_lock_tables() ，并且线程状态尚未更新。这是一个非常普遍的状态，可能由于多种原因而发生。&lt;/p&gt;
&lt;p&gt;例如，线程将请求或正在等待表的内部或外部系统锁定。InnoDB在执行期间等待表级锁定时会 发生这种情况LOCK TABLES。如果此状态是由外部锁的请求引起的，并且您没有使用多个访问相同 表的mysqld服务器，则MyISAM可以使用该–skip-external-locking 选项禁用外部系统锁 。但是，默认情况下禁用外部锁定，因此该选项很可能无效。对于 SHOW PROFILE，这个状态意味着线程正在请求锁定（不等待它）。&lt;/p&gt;
&lt;p&gt;update&lt;/p&gt;
&lt;p&gt;线程正准备开始更新表。&lt;/p&gt;
&lt;p&gt;Updating&lt;/p&gt;
&lt;p&gt;线程正在搜索要更新的行并正在更新它们。&lt;/p&gt;
&lt;p&gt;updating main table&lt;/p&gt;
&lt;p&gt;服务器正在执行多表更新的第一部分。它仅更新第一个表，并保存用于更新其他（引用）表的列和偏移量。&lt;/p&gt;
&lt;p&gt;updating reference tables&lt;/p&gt;
&lt;p&gt;服务器正在执行多表更新的第二部分，并更新其他表中的匹配行。&lt;/p&gt;
&lt;p&gt;User lock&lt;/p&gt;
&lt;p&gt;该线程将要求或正在等待通过GET_LOCK()呼叫请求的咨询锁 。对于 SHOW PROFILE，此状态表示线程正在请求锁定（不等待它）。&lt;/p&gt;
&lt;p&gt;User sleep&lt;/p&gt;
&lt;p&gt;线程已经调用了一个 SLEEP()调用。&lt;/p&gt;
&lt;p&gt;Waiting for commit lock&lt;/p&gt;
&lt;p&gt;FLUSH TABLES WITH READ LOCK 正在等待提交锁定。&lt;/p&gt;
&lt;p&gt;Waiting for global read lock&lt;/p&gt;
&lt;p&gt;FLUSH TABLES WITH READ LOCK整等待全局读锁建议：不要对线上业务数据库加上全局读锁，通常是备份引起，可以放在业务低谷期间执行或者放在slave服务器上执行备份&lt;/p&gt;
&lt;p&gt;Waiting for tables&lt;/p&gt;
&lt;p&gt;线程得到一个通知，表明表的底层结构已经改变，它需要重新打开表以获得新结构。但是，要重新打开表，它必须等到所有其他线程关闭了相关表。&lt;/p&gt;
&lt;p&gt;该通知发生如果另一个线程已使用 FLUSH TABLES或有问题的表下面的语句之一：FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, or OPTIMIZE TABLE.&lt;br&gt;Waiting for table flush&lt;/p&gt;
&lt;p&gt;线程正在执行FLUSH TABLES并且正在等待所有线程关闭它们的表，或者线程得到一个表的基础结构已经更改的通知，并且它需要重新打开表以获取新结构。但是，要重新打开表，它必须等到所有其他线程关闭了相关表。&lt;/p&gt;
&lt;p&gt;该通知发生如果另一个线程已使用 FLUSH TABLES或有问题的表下面的语句之一： FLUSH TABLES tbl_nameALTER TABLERENAME TABLEREPAIR TABLEANALYZE TABLEOPTIMIZE TABLE&lt;/p&gt;
&lt;p&gt;Waiting for lock_type lock&lt;/p&gt;
&lt;p&gt;服务器正在等待THR_LOCK从元数据锁定子系统获取 锁定或锁定，其中 lock_type指示锁定的类型。&lt;/p&gt;
&lt;p&gt;此状态表示等待 THR_LOCK：&lt;/p&gt;
&lt;p&gt;Waiting for table level lock&lt;/p&gt;
&lt;p&gt;这些状态表示等待元数据锁定：&lt;/p&gt;
&lt;p&gt;Waiting for event metadata lock&lt;/p&gt;
&lt;p&gt;Waiting for global read lock&lt;/p&gt;
&lt;p&gt;Waiting for schema metadata lock&lt;/p&gt;
&lt;p&gt;Waiting for stored function metadata lock&lt;/p&gt;
&lt;p&gt;Waiting for stored procedure metadata lock&lt;/p&gt;
&lt;p&gt;Waiting for table metadata lock&lt;/p&gt;
&lt;p&gt;Waiting for trigger metadata lock&lt;/p&gt;
&lt;p&gt;有关表锁指示器的信息，请参见 第8.11.1节“内部锁定方法”。有关元数据锁定的信息，请参见第8.11.4节“元数据锁定”。要查看哪些锁阻止了锁请求，请使用 第25.12.12节“性能模式锁表”中所述的性能模式锁表。&lt;/p&gt;
&lt;p&gt;Waiting on cond&lt;/p&gt;
&lt;p&gt;线程正在等待条件变为真的通用状态。没有具体的州信息。&lt;/p&gt;
&lt;p&gt;Writing to net&lt;/p&gt;
&lt;p&gt;服务器正在将数据包写入网络。Sending to client从MySQL 5.7.8开始调用此状态。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;以下列举了State 与常规查询处理相关联的线程值，而不是更具体的活动（如复制）。其中许多仅用于查找服务器中的错误。&lt;/p&gt;
&lt;p&gt;After create&lt;/p&gt;
&lt;p&gt;当线程在创建表的函数末尾创建表（包括内部临时表）时，会发生这种情况。即使由于某些错误而无法创
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="线程" scheme="http://idber.github.io/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB自定义权限实现MongoDB集合即表权限管理</title>
    <link href="http://idber.github.io/2019/05/30-MongoDB%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9D%83%E9%99%90%E5%AE%9E%E7%8E%B0MongoDB%E9%9B%86%E5%90%88%E5%8D%B3%E8%A1%A8%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86.html"/>
    <id>http://idber.github.io/2019/05/30-MongoDB自定义权限实现MongoDB集合即表权限管理.html</id>
    <published>2019-05-30T02:01:56.000Z</published>
    <updated>2019-05-30T12:44:28.835Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;业务上做迁移需要对原有数据进行锁定防止新数据写入，锁定的是db里的一个集合，MongoDB没有MySQL的权限细化管理到表，翻遍MongoDB文档，只能自建角色。&lt;/p&gt;
&lt;h1 id=&quot;官方文档&quot;&gt;&lt;a href=&quot;#官方文档&quot; class=&quot;headerlink&quot; title=&quot;官方文档&quot;&gt;&lt;/a&gt;官方文档&lt;/h1&gt;&lt;h2 id=&quot;用户自定义角色&quot;&gt;&lt;a href=&quot;#用户自定义角色&quot; class=&quot;headerlink&quot; title=&quot;用户自定义角色&quot;&gt;&lt;/a&gt;用户自定义角色&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/core/security-user-defined-roles/#user-defined-roles&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.mongodb.com/manual/core/security-user-defined-roles/#user-defined-roles&lt;/a&gt; &lt;/p&gt;
&lt;h2 id=&quot;创建角色语法&quot;&gt;&lt;a href=&quot;#创建角色语法&quot; class=&quot;headerlink&quot; title=&quot;创建角色语法&quot;&gt;&lt;/a&gt;创建角色语法&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/reference/method/db.createRole/#db.createRole&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.mongodb.com/manual/reference/method/db.createRole/#db.createRole&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;创建自定义角色&quot;&gt;&lt;a href=&quot;#创建自定义角色&quot; class=&quot;headerlink&quot; title=&quot;创建自定义角色&quot;&gt;&lt;/a&gt;创建自定义角色&lt;/h1&gt;&lt;p&gt;在业务库里执行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use db_name // db_name这里是你业务数据库的名称
db.createRole(
   {
     role: &amp;quot;my_define_role&amp;quot;, // 角色名称
     privileges: [
       { resource: { cluster: true }, actions: [ &amp;quot;addShard&amp;quot; ] }, // 分片集群MongoDB需要填写此项，副本集不用
       { resource: { db: &amp;quot;config&amp;quot;, collection: &amp;quot;&amp;quot; }, actions: [ &amp;quot;find&amp;quot;, &amp;quot;update&amp;quot;, &amp;quot;insert&amp;quot;, &amp;quot;remove&amp;quot; ] }, // 定义库权限，可以到集合权限。
       { resource: { db: &amp;quot;users&amp;quot;, collection: &amp;quot;usersCollection&amp;quot; }, actions: [ &amp;quot;update&amp;quot;, &amp;quot;insert&amp;quot;, &amp;quot;remove&amp;quot; ] },  // // 多个集合可以分别指定
       { resource: { db: &amp;quot;&amp;quot;, collection: &amp;quot;&amp;quot; }, actions: [ &amp;quot;find&amp;quot; ] }
     ], // 也可以指定不同的库，&amp;quot;&amp;quot;表示所有库、集合
     roles: [
       { role: &amp;quot;read&amp;quot;, db: &amp;quot;db_name&amp;quot; }  // db_name这里是你业务数据库的名称
     ]
   },
   { w: &amp;quot;majority&amp;quot; , wtimeout: 5000 } // 副本集默认的写入方式是majority
)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;相关文档&lt;br&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/reference/write-concern/#writeconcern.%22majority%22&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.mongodb.com/manual/reference/write-concern/#writeconcern.%22majority%22&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;更新业务库角色权限&quot;&gt;&lt;a href=&quot;#更新业务库角色权限&quot; class=&quot;headerlink&quot; title=&quot;更新业务库角色权限&quot;&gt;&lt;/a&gt;更新业务库角色权限&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;db.getSiblingDB(&amp;quot;db_name&amp;quot;).updateUser( // db_name为业务库名
    &amp;quot;db_name&amp;quot;,
    {
        customData: {},

        roles: [
        { &amp;quot;role&amp;quot;: &amp;quot;my_define_role&amp;quot;, &amp;quot;db&amp;quot;: &amp;quot;db_name&amp;quot; ,},// my_define_role为自定义角色名
        ],
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;)&lt;/p&gt;
&lt;p&gt;完&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;业务上做迁移需要对原有数据进行锁定防止新数据写入，锁定的是db里的一个集合，MongoDB没有MySQL的权限细化管理到表，翻遍M
    
    </summary>
    
      <category term="MongoDB" scheme="http://idber.github.io/categories/MongoDB/"/>
    
    
      <category term="MongoDB" scheme="http://idber.github.io/tags/MongoDB/"/>
    
      <category term="权限" scheme="http://idber.github.io/tags/%E6%9D%83%E9%99%90/"/>
    
  </entry>
  
  <entry>
    <title>Raft协议</title>
    <link href="http://idber.github.io/2019/05/21-Raft%E5%8D%8F%E8%AE%AE.html"/>
    <id>http://idber.github.io/2019/05/21-Raft协议.html</id>
    <published>2019-05-21T02:01:56.000Z</published>
    <updated>2019-05-23T04:00:19.319Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;概念与术语&quot;&gt;&lt;a href=&quot;#概念与术语&quot; class=&quot;headerlink&quot; title=&quot;概念与术语&quot;&gt;&lt;/a&gt;概念与术语&lt;/h1&gt;&lt;p&gt;Leader：领导者，为客户端提供服务(生成写日志)的节点，任何时候Raft系统中只能有一个Leader。&lt;br&gt;Follower：跟随者，被动接受请求的节点，不会发送任何请求，只会响应来自Leader或者Candidate的请求。如果接受到客户请求，会转发给Leader。&lt;br&gt;Candidate：候选人，选举过程中产生，Follower在超时时间内没有收到Leader的心跳或者日志，则切换到Candidate状态，进入选举流程。&lt;br&gt;TermId：任期号，时间被划分成一个个任期，每次选举后都会产生一个新的TermId，一个任期内只有一个Leader。TermId相当于Paxos的ProposalId。&lt;br&gt;currentTerm：更新的Term。&lt;br&gt;RequestVote：请求投票，Candidate在选举过程中发起，收到Quorum(多数派）响应后，成为Leader。&lt;br&gt;AppendEntries：附加日志，Leader发送日志和心跳的机制&lt;br&gt;Election Timeout：选举超时，如果Follower在一段时间内(超时时间为150ms-300ms内随机数)没有收到任何消息(追加日志或者心跳)，就是选举超时。&lt;br&gt;Leader Election：领导选举，选举超时即开始领导选举。&lt;br&gt;Raft协议主要包括三部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leader选举&lt;/li&gt;
&lt;li&gt;日志复制&lt;/li&gt;
&lt;li&gt;成员变更&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个节点的状态只有如下三种形式的一种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Follower 状态&lt;/li&gt;
&lt;li&gt;Candidate 状态&lt;/li&gt;
&lt;li&gt;Leader 状态&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Leader选举&quot;&gt;&lt;a href=&quot;#Leader选举&quot; class=&quot;headerlink&quot; title=&quot;Leader选举&quot;&gt;&lt;/a&gt;Leader选举&lt;/h1&gt;&lt;h2 id=&quot;Leader流程&quot;&gt;&lt;a href=&quot;#Leader流程&quot; class=&quot;headerlink&quot; title=&quot;Leader流程&quot;&gt;&lt;/a&gt;Leader流程&lt;/h2&gt;&lt;p&gt;服务器启动时初始状态都是Follower，如果在超时时间内没有收到Leader发送的心跳包，则进入Candidate状态进行选举，服务器启动时和Leader挂掉时处理一样。为了避免选票瓜分的情况，比如5个节点ABCDE，Leader A 挂掉后，还剩4个节点，raft协议约定，每个服务器在一个任期只能投一张票，假设B，D分别有最新的日志，且同时发起选举投票，则可能出现B和D分别得到2张票的情况，如果这样都得不到大多数确认，无法选出leader。为了避免这种情况发生，raft利用随机超时机制避免选票瓜分情况。选举超时时间从一个固定的区间随机选择，由于&lt;font color=&quot;red&quot;&gt;每个服务器的超时时间不同&lt;/font&gt;，则leader挂掉后，超时时间最短且拥有最多日志的follower最先开始选主，并成为leader。一旦candidate成为leader，就会向其他服务器发送心跳包阻止新一轮的选举开始。&lt;br&gt;发送日志信息:(term,candidateId,lastLogTerm,lastLogIndex)&lt;/p&gt;
&lt;h2 id=&quot;Candidate流程&quot;&gt;&lt;a href=&quot;#Candidate流程&quot; class=&quot;headerlink&quot; title=&quot;Candidate流程&quot;&gt;&lt;/a&gt;Candidate流程&lt;/h2&gt;&lt;p&gt;1.在超时时间内没有收到leader的日志(包括心跳)&lt;br&gt;2.将状态切换为candidate,自增currentTerm,设置超时时间&lt;br&gt;3.向所有节点广播选举请求，等待响应，可能会有以下三种情况：&lt;br&gt;(1).如果收到多数派回应，则成为leader&lt;br&gt;(2).如果收到leader的心跳，且leader的term&amp;gt;=currentTerm，则自己切换为follower状态，&lt;br&gt;否则，保持Candidate身份&lt;br&gt;(3).如果在超时时间内没有达成多数派，也没有收到leader心跳，则很可能选票被瓜分，则会自增currentTerm,进行新一轮的选举&lt;/p&gt;
&lt;h2 id=&quot;Follower流程&quot;&gt;&lt;a href=&quot;#Follower流程&quot; class=&quot;headerlink&quot; title=&quot;Follower流程&quot;&gt;&lt;/a&gt;Follower流程&lt;/h2&gt;&lt;p&gt;1.如果term &amp;lt; currentTerm，说明有更新的term，返回给candidate。&lt;br&gt;2.如果还没有投票，或者candidateId的日志(lastLogTerm,lastLogIndex)和本地日志一样或更新，则投票给它。&lt;br&gt;注意：一个term周期内，每个节点最多只能投一张票，按照先来先到原则&lt;/p&gt;
&lt;p&gt;关键词：随机超时，FIFO&lt;/p&gt;
&lt;h1 id=&quot;日志复制流程&quot;&gt;&lt;a href=&quot;#日志复制流程&quot; class=&quot;headerlink&quot; title=&quot;日志复制流程&quot;&gt;&lt;/a&gt;日志复制流程&lt;/h1&gt;&lt;p&gt;leader向follower发送日志时，会顺带邻近的前一条日志，follwer接收日志时，会在相同任期号和索引位置找前一条日志，如果存在且匹配，则接收日志；否则拒绝，leader会减少日志索引位置并进行重试，直到某个位置与follower达成一致。然后follower删除索引后的所有日志，并追加leader发送的日志，一旦日志追加成功，则follower和leader的所有日志就保持一致。只有在多数派的follower都响应接受到日志后，表示事务可以提交，才能返回客户端提交成功。&lt;br&gt;发送日志信息:(term,leaderId,prevLogIndex,prevLogTerm,leaderCommitIndex)&lt;/p&gt;
&lt;h2 id=&quot;leader流程&quot;&gt;&lt;a href=&quot;#leader流程&quot; class=&quot;headerlink&quot; title=&quot;leader流程&quot;&gt;&lt;/a&gt;leader流程&lt;/h2&gt;&lt;p&gt;1.接收到client请求，本地持久化日志&lt;br&gt;2.将日志发往各个节点&lt;br&gt;3.如果达成多数派，再commit，返回给client。&lt;br&gt;备注：&lt;br&gt;(1).如果传递给follower的lastLogIndex&amp;gt;=nextIndex,则从nextIndex继续传递&lt;br&gt;.如果返回成功，则更新follower对应的nextIndex和matchIndex&lt;br&gt;.如果失败，则表示follower还差更多的日志，则递减nextIndex，重试&lt;br&gt;(2).如果存在N&amp;gt;commitIndex，且多数派matchIndex[i]&amp;gt;=N, 且log[N].term == currentTerm,&lt;br&gt;设置commitIndex=N。&lt;/p&gt;
&lt;h2 id=&quot;follower处理流程&quot;&gt;&lt;a href=&quot;#follower处理流程&quot; class=&quot;headerlink&quot; title=&quot;follower处理流程&quot;&gt;&lt;/a&gt;follower处理流程&lt;/h2&gt;&lt;p&gt;1.比较term号和自身的currentTerm，如果term&amp;lt;currentTerm，则返回false&lt;br&gt;2.如果(prevLogIndex,prevLogTerm)不存在，说明还差日志，返回false&lt;br&gt;3.如果(prevLogIndex,prevLogTerm)与已有的日志冲突，则以leader为准，删除自身的日志&lt;br&gt;4.将leader传过来的日志追加到末尾&lt;br&gt;5.如果leaderCommitIndex&amp;gt;commitIndex,说明是新的提交位点，回放日志，设置commitIndex =&lt;br&gt;min(leaderCommitIndex, index of last new entry)&lt;/p&gt;
&lt;p&gt;备注：默认情况下，如果日志不匹配，会按logIndex逐条往前推进，直到找到match的位置，有一个简单的思路是，每次往前推进一个term，这样可以减少了网络交互，尽快早点match的位置，代价是可能传递了一些多余的日志。&lt;/p&gt;
&lt;p&gt;关键词：日志连续一致性，多数派，leader日志不变更&lt;/p&gt;
&lt;h1 id=&quot;快照流程&quot;&gt;&lt;a href=&quot;#快照流程&quot; class=&quot;headerlink&quot; title=&quot;快照流程&quot;&gt;&lt;/a&gt;快照流程&lt;/h1&gt;&lt;p&gt;避免日志占满磁盘空间，需要定期对日志进行清理，在清理前需要做快照，这样新加入的节点可以通过快照+日志恢复。&lt;br&gt;快照属性：&lt;br&gt;1.最后一个已经提交的日志（termId，logIndex）&lt;br&gt;2.新的快照生成后，可以删除之前的日志和以前的快照。&lt;br&gt;删日志不能太快，否则，crash后的机器，本来可以通过日志恢复，如果日志不存在，需要通过快照恢复，比较慢。&lt;/p&gt;
&lt;h2 id=&quot;leader发送快照流程&quot;&gt;&lt;a href=&quot;#leader发送快照流程&quot; class=&quot;headerlink&quot; title=&quot;leader发送快照流程&quot;&gt;&lt;/a&gt;leader发送快照流程&lt;/h2&gt;&lt;p&gt;传递参数(leaderTermId, lastIndex, lastTerm, offset, data[], done_flag)&lt;br&gt;1.如果发现日志落后太远(超过阀值)，则触发发送快照流程&lt;br&gt;备注：快照不能太频繁，否则会导致磁盘IO压力较大；但也需要定期做，清理非必要的日志，缓解日志的空间压力，另外可以提高follower追赶的速度。&lt;/p&gt;
&lt;h2 id=&quot;follower接收快照流程&quot;&gt;&lt;a href=&quot;#follower接收快照流程&quot; class=&quot;headerlink&quot; title=&quot;follower接收快照流程&quot;&gt;&lt;/a&gt;follower接收快照流程&lt;/h2&gt;&lt;p&gt;1.如果leaderTermId&amp;lt;currentTerm, 则返回&lt;br&gt;2.如果是第一个块，创建快照&lt;br&gt;3.在指定的偏移，将数据写入快照&lt;br&gt;4.如果不是最后一块，等待更多的块&lt;br&gt;5.接收完毕后，丢掉以前旧的快照&lt;br&gt;6.删除掉不需要的日志&lt;/p&gt;
&lt;h1 id=&quot;集群配置变更&quot;&gt;&lt;a href=&quot;#集群配置变更&quot; class=&quot;headerlink&quot; title=&quot;集群配置变更&quot;&gt;&lt;/a&gt;集群配置变更&lt;/h1&gt;&lt;p&gt;C(old): 旧配置&lt;br&gt;C(new): 新配置&lt;br&gt;C(old-new): 过渡配置，需要同时在old和new中达成多数派才行&lt;br&gt;原则：配置变更过程中，不会导致出现两个leader&lt;br&gt;二阶段方案：引入过渡阶段C(old-new)&lt;br&gt;约定：任何一个follower在收到新的配置后，就采用新的配置确定多数派。&lt;/p&gt;
&lt;h2 id=&quot;变更流程&quot;&gt;&lt;a href=&quot;#变更流程&quot; class=&quot;headerlink&quot; title=&quot;变更流程&quot;&gt;&lt;/a&gt;变更流程&lt;/h2&gt;&lt;p&gt;1.leader收到从C(old)切换到C(new)配置的请求&lt;br&gt;2.创建配置日志C(old-new),这条日志需要在C(old)和C(new)中同时达成多数派&lt;br&gt;3.任何一个follower收到配置后，采用的C(old-new)来确定日志是否达成多数派(即使C(old-new)这条日志还没达成多数派)&lt;br&gt;备注：1，2，3阶段只有可能C(old)节点成为leader，因为C(old-new)没有可能成为多数派。&lt;br&gt;4.C(old-new)日志commit(达成多数派)，则无论是C(old)还是C(new)都无法单独达成多数派，即不会存在两个leader&lt;br&gt;5.创建配置配置日志C(new),广播到所有节点&lt;br&gt;6.同样的，任何一个follower收到配置后，采用的C(new)来确定日志是否达成多数派&lt;br&gt;备注：在4，5，6阶段，只有可能含有C(old-new)配置的节点成为leader。&lt;br&gt;7.C(new)配置日志commit后，则C(old-new)无法再达成多数派&lt;br&gt;8.对于不在C(new)配置的节点，就可以退出了，变更完成。&lt;br&gt;备注：在7，8阶段，只有可能含有C(new)配置成为leader。&lt;br&gt;所以整个过程中永远只会有一个leader。对于leader不在C(new)配置的情况，需要在C(new)日志提交后，自动关闭。&lt;/p&gt;
&lt;p&gt;相关阅读&lt;br&gt;&lt;a href=&quot;http://thesecretlivesofdata.com/raft/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://thesecretlivesofdata.com/raft/&lt;/a&gt;  （强烈推荐阅读，动画的形式化繁为简地讲解raft）&lt;br&gt;&lt;a href=&quot;https://raft.github.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://raft.github.io/&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://raft.github.io/raft.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://raft.github.io/raft.pdf&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://medium.com/@techgeek628/raft-understandable-distributed-consensus-987b3783d48a&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://medium.com/@techgeek628/raft-understandable-distributed-consensus-987b3783d48a&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;概念与术语&quot;&gt;&lt;a href=&quot;#概念与术语&quot; class=&quot;headerlink&quot; title=&quot;概念与术语&quot;&gt;&lt;/a&gt;概念与术语&lt;/h1&gt;&lt;p&gt;Leader：领导者，为客户端提供服务(生成写日志)的节点，任何时候Raft系统中只能有一个Leader。
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="分布式" scheme="http://idber.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Quorum协议</title>
    <link href="http://idber.github.io/2019/05/16-Quorum%E5%8D%8F%E8%AE%AE.html"/>
    <id>http://idber.github.io/2019/05/16-Quorum协议.html</id>
    <published>2019-05-16T02:01:56.000Z</published>
    <updated>2019-05-17T01:41:02.968Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;Amazon Aurora 存储层的复制基于Quorum协议，那么什么是Quorum协议呢？&lt;/p&gt;
&lt;p&gt;Quorum 协议，是一种分布式系统中常用的，用来保证数据冗余和最终一致性的投票算法，其主要数学思想来源于鸽巢原理。&lt;/p&gt;
&lt;p&gt;什么又是鸽巢原理？&lt;/p&gt;
&lt;p&gt;鸽巢原理，又名狄利克雷抽屉原理、鸽笼原理。&lt;/p&gt;
&lt;p&gt;其中一种简单的表述法为：&lt;/p&gt;
&lt;p&gt;若有n个笼子和n + 1只鸽子，所有的鸽子都被关在鸽笼里，那么至少有一个笼子有至少2只鸽子。&lt;/p&gt;
&lt;p&gt;另一种为：&lt;/p&gt;
&lt;p&gt;若有n个笼子和kn+1只鸽子，所有的鸽子都被关在鸽笼里，那么至少有一个笼子有至少k+1只鸽子。&lt;br&gt;随机取3组数据&lt;/p&gt;
&lt;p&gt;n = 1, k = 1&lt;br&gt;1个笼子&lt;br&gt;kn + 1 = 2 共2只鸽子&lt;br&gt;k + 1 = 2 至少有一个笼子有至少2只鸽子&lt;/p&gt;
&lt;p&gt;n = 2, k = 2&lt;br&gt;2个笼子&lt;br&gt;kn + 1 = 5 共5只鸽子&lt;br&gt;k + 1 = 3 至少有一个笼子有至少3只鸽子&lt;/p&gt;
&lt;p&gt;n = 10, k = 2&lt;br&gt;10个笼子&lt;br&gt;kn + 1 = 21 共21只鸽子&lt;br&gt;k + 1 = 3 至少有一个笼子有至少3只鸽子&lt;/p&gt;
&lt;p&gt;集合论的表述如下：&lt;/p&gt;
&lt;p&gt;若A是n+1元集，B是n元集，则不存在从A到B的单射。&lt;br&gt;拉姆齐定理是此原理的推广。&lt;/p&gt;
&lt;p&gt;基于Quorum投票的冗余控制算法&lt;br&gt;在有冗余数据的分布式存储系统当中，冗余数据对象会在不同的机器之间存放多份拷贝。但是同一时刻一个数据对象的多份拷贝只能用于读或者用于写。&lt;/p&gt;
&lt;p&gt;该算法可以保证同一份数据对象的多份拷贝不会被超过两个访问对象读写。&lt;/p&gt;
&lt;p&gt;算法来源于[Gifford, 1979]。 分布式系统中的每一份数据拷贝对象都被赋予一票。每一个读操作获得的票数必须大于最小读票数（read quorum）（Vr），每个写操作获得的票数必须大于最小写票数（write quorum）(Vw）才能读或者写。如果系统有V票（意味着一个数据对象有V份冗余拷贝），那么最小读写票数(quorum)应满足如下限制：&lt;/p&gt;
&lt;p&gt;Vr + Vw &amp;gt; V&lt;br&gt;Vw &amp;gt; V/2&lt;br&gt;第一条规则保证了一个数据不会被同时读写。当一个写操作请求过来的时候，它必须要获得Vw个冗余拷贝的许可。而剩下的数量是V-Vw 不够Vr，因此不能再有读请求过来了。同理，当读请求已经获得了Vr个冗余拷贝的许可时，写请求就无法获得许可了。&lt;/p&gt;
&lt;p&gt;第二条规则保证了数据的串行化修改。一份数据的冗余拷贝不可能同时被两个写请求修改。&lt;/p&gt;
&lt;p&gt;算法的好处&lt;br&gt;在分布式系统中，冗余数据是保证可靠性的手段，因此冗余数据的一致性维护就非常重要。一般而言，一个写操作必须要对所有的冗余数据都更新完成了，才能称为成功结束。比如一份数据在5台设备上有冗余，因为不知道读数据会落在哪一台设备上，那么一次写操作，必须5台设备都更新完成，写操作才能返回。&lt;/p&gt;
&lt;p&gt;对于写操作比较频繁的系统，这个操作的瓶颈非常大。Quorum算法可以让写操作只要写完3台就返回。剩下的由系统内部缓慢同步完成。而读操作，则需要也至少读3台，才能保证至少可以读到一个最新的数据。&lt;/p&gt;
&lt;p&gt;Quorum的读写最小票数可以用来做为系统在读、写性能方面的一个可调节参数。写票数Vw越大，则读票数Vr越小，这时候系统读的开销就小。反之则写的开销就小。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;Amazon Aurora 存储层的复制基于Quorum协议，那么什么是Quorum协议呢？&lt;/p&gt;
&lt;p&gt;Quorum 协议，是一种分布式系统中常用的，用来保证数据冗余和最终一致性的投票算法，其主要数学思想来源于鸽巢原理。&lt;/p&gt;
&lt;p&gt;什么又是鸽巢原理？&lt;/p
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="分布式" scheme="http://idber.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>MySQL字符集一个隐藏参数</title>
    <link href="http://idber.github.io/2019/05/14-MySQL%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B8%80%E4%B8%AA%E9%9A%90%E8%97%8F%E5%8F%82%E6%95%B0.html"/>
    <id>http://idber.github.io/2019/05/14-MySQL字符集一个隐藏参数.html</id>
    <published>2019-05-14T02:01:56.000Z</published>
    <updated>2019-05-14T03:54:52.963Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;最近在研究字符集相关的问题，无意中看到了MySQL字符集一个隐藏的参数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--character-set-client-handshake
Do not ignore character set information sent by the client. To ignore client information and use the default server character set, use --skip-character-set-client-handshake; this makes MySQL behave like MySQL 4.0.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为了兼容 mysql 4.0 的习惯增加的这个参数，character-set-client-handshake默认为1，读取default_character_set里设置的值。如果忽略客户端字符集设置，mysqld启动时加上 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--skip-character-set-client-handshake 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;验证：&lt;br&gt;my.cnf参数设置&lt;br&gt;default_character_set = latin1&lt;br&gt;character_set_server = utf8mb4&lt;/p&gt;
&lt;p&gt;启动不读取default_character_set的值设置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;character-set-client-handshake=0
or
skip-character-set-client-handshake=1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启mysql让配置生效，查看结果&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | utf8mb4                           |
| character_set_connection | utf8mb4                           |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | utf8mb4                           |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.01 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到character_set_client，character_set_connection，character_set_results读取的是character_set_server的值utf8mb4&lt;/p&gt;
&lt;p&gt;如果启动读取default_character_set的值设置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;character-set-client-handshake=1
or
skip-character-set-client-handshake=0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启mysql让配置生效，查看结果&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | latin1                            |
| character_set_connection | latin1                            |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | latin1                            |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.13 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到character_set_client，character_set_connection，character_set_results读取的是default_character_set的值latin1&lt;/p&gt;
&lt;p&gt;这时需要手工设置&lt;br&gt;set names xxx;&lt;br&gt;才会将client、connection、results的字符集改过来。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set names utf8;

Query OK, 0 rows affected (0.02 sec)

show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | utf8                              |
| character_set_connection | utf8                              |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | utf8                              |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其实这个参数也是有好处的。比如启用 skip-character-set-client-handshake 选项后，就可以避免客户端程序误操作，使用其他字符集连接进来并写入数据，从而引发乱码问题。&lt;/p&gt;
&lt;p&gt;相关阅读：&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/cchust/p/4327019.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/cchust/p/4327019.html&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://idber.github.io/2019/05/10-MySQL的伪utf8字符集.html&quot;&gt;http://idber.github.io/2019/05/10-MySQL的伪utf8字符集.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;最近在研究字符集相关的问题，无意中看到了MySQL字符集一个隐藏的参数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--character-set-client-handshake
Do not ignore character set information sent by 
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="字符集" scheme="http://idber.github.io/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>MySQL字符集的内部转换</title>
    <link href="http://idber.github.io/2019/05/13-MySQL%E5%AD%97%E7%AC%A6%E9%9B%86%E7%9A%84%E5%86%85%E9%83%A8%E8%BD%AC%E6%8D%A2.html"/>
    <id>http://idber.github.io/2019/05/13-MySQL字符集的内部转换.html</id>
    <published>2019-05-13T02:01:56.000Z</published>
    <updated>2019-05-15T07:36:46.494Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;我们知道set names utf8;改变的character_set_client、character_set_connection、character_set_result三个值，MySQL字符集的内部转换到底是哪个阶段呢，下面通过控制变量法来验证。&lt;/p&gt;
&lt;h1 id=&quot;表准备&quot;&gt;&lt;a href=&quot;#表准备&quot; class=&quot;headerlink&quot; title=&quot;表准备&quot;&gt;&lt;/a&gt;表准备&lt;/h1&gt;&lt;p&gt;建立gbk字符集的表&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show create table t\G
*************************** 1. row ***************************
       Table: t
Create Table: CREATE TABLE `t` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `data` varchar(100) DEFAULT NULL,
  `comment` varchar(100) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_data` (`data`)
) ENGINE=InnoDB  DEFAULT CHARSET=gbk
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;character_set_client、character_set_connection、character_set_result为gbk，SecureCRT为utf-8&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | gbk                               |
| character_set_connection | gbk                               |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | gbk                               |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

insert into T values(null,&amp;apos;小明&amp;apos;,&amp;apos;3 gbk&amp;apos;);

SELECT LENGTH(data), CHAR_LENGTH(data),data,hex(data),hex(&amp;apos;小明&amp;apos;),comment  from t;
+--------------+-------------------+--------+--------------+---------------+---------+
| LENGTH(data) | CHAR_LENGTH(data) | data   | hex(data)    | hex(&amp;apos;小明&amp;apos;) | comment |
+--------------+-------------------+--------+--------------+---------------+---------+
|            6 |                 3 | 小明   | E5B08FE6988E | E5B08FE6988E  | 3 gbk   |
+--------------+-------------------+--------+--------------+---------------+---------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里在SecureCRT明文输入hex(‘小明’)&lt;br&gt;可以看到查询出的二进制流为E5B08FE6988E&lt;br&gt;由于character_set_client、character_set_connection、character_set_result和表字符集均为GBK，不涉及MySQL内部编码转换。因此，表字符集虽然为GBK，但“小明”的编码并非为GBK编码的二进制流，而是UTF8的二进制流，两个汉字占用了6个字节，而读取是一个逆向的过程，不涉及到编码转换，查询依然能正确返回“小明”。&lt;/p&gt;
&lt;h1 id=&quot;只更改character-set-client为utf8&quot;&gt;&lt;a href=&quot;#只更改character-set-client为utf8&quot; class=&quot;headerlink&quot; title=&quot;只更改character_set_client为utf8&quot;&gt;&lt;/a&gt;只更改character_set_client为utf8&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;set character_set_client=utf8;

Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | utf8                              |
| character_set_connection | gbk                               |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | gbk                               |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

insert into T values(null,&amp;apos;小明&amp;apos;,&amp;apos;character_set_client utf8&amp;apos;);  

Query OK, 1 row affected (0.01 sec)

SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),hex(&amp;apos;小明&amp;apos;),comment  from t order by id ;
+----+--------------+-------------------+--------+--------------+-------------+---------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data   | hex(data)    | hex(&amp;apos;С) | comment                   |
+----+--------------+-------------------+--------+--------------+-------------+---------------------------+
|  1 |            6 |                 3 | 小明    | E5B08FE6988E | D0A1C3F7    | 3 gbk                     |
|  2 |            4 |                 2 | С      | D0A1C3F7     | D0A1C3F7    | character_set_client utf8 |
+----+--------------+-------------------+--------+--------------+-------------+---------------------------+
2 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，数据库里存储的字符为utf8的二进制流E5B08FE6988E&lt;br&gt;MySQL把SecureCRT明文输入的“小明”转换成了gbk的二进制流D0A1C3F7&lt;br&gt;把SecureCRT字符集设置成gbk用unhex反向查看确认D0A1C3F7是不是gbk的二进制流&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select unhex(&amp;apos;D0A1C3F7&amp;apos;);
+-------------------+
| unhex(&amp;apos;D0A1C3F7&amp;apos;) |
+-------------------+
| 小明              |
+-------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以D0A1C3F7为小明gbk的二进制流&lt;br&gt;而E5B08FE6988E呢&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select unhex(&amp;apos;E5B08FE6988E&amp;apos;);
+-----------------------+
| unhex(&amp;apos;E5B08FE6988E&amp;apos;) |
+-----------------------+
| 灏忔槑                |
+-----------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于SecureCRT是gbk字符集，把utf-8二进制流E5B08FE6988E按gbk解码成了gbk对应的汉字“灏忔槑”，就是日常所说的乱码。把SecureCRT设置成utf-8后，即恢复正常&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select unhex(&amp;apos;E5B08FE6988E&amp;apos;);
+-----------------------+
| unhex(&amp;apos;E5B08FE6988E&amp;apos;) |
+-----------------------+
| 小明                |
+-----------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以E5B08FE6988E为小明utf8的二进制流&lt;/p&gt;
&lt;p&gt;SecureCRT(utf8 E5B08FE6988E)–&amp;gt; character_set_client(utf8 E5B08FE6988E)–&amp;gt;character_set_connection(gbk D0A1C3F7)–&amp;gt;database(gbk D0A1C3F7)–&amp;gt;character_set_results(gbk D0A1C3F7)–&amp;gt;SecureCRT(utf8 D0A1C3F7)&lt;/p&gt;
&lt;p&gt;client(utf8)–&amp;gt;connection(gbk)作了转化&lt;/p&gt;
&lt;p&gt;connection把utf8的二进制流转换为gbk的二进制流，由于gbk不包含utf8，需要先用原utf8解码再转码为gbk，用Python演示过程为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a = u&amp;quot;小明&amp;quot;
a_utf_8 = a.encode(&amp;apos;utf-8&amp;apos;)
print(a_utf_8)
a_unicode = a_utf_8.decode(&amp;apos;utf-8&amp;apos;)
assert (a_unicode == a)
a_gb2312 = a_unicode.encode(&amp;apos;gb2312&amp;apos;)
print(a_gb2312)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;b&amp;apos;\xe5\xb0\x8f\xe6\x98\x8e&amp;apos;
b&amp;apos;\xd0\xa1\xc3\xf7&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;只设置character-set-connection为utf8&quot;&gt;&lt;a href=&quot;#只设置character-set-connection为utf8&quot; class=&quot;headerlink&quot; title=&quot;只设置character_set_connection为utf8&quot;&gt;&lt;/a&gt;只设置character_set_connection为utf8&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;set names gbk;
Query OK, 0 rows affected (0.00 sec)

set character_set_connection=utf8;
Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | gbk                               |
| character_set_connection | utf8                              |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | gbk                               |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

 insert into T values(null,&amp;apos;小明&amp;apos;,&amp;apos;character_set_connection utf8&amp;apos;);
Query OK, 1 row affected (0.01 sec)

guo@ha 12:25:58&amp;gt;SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),hex(&amp;apos;小明&amp;apos;),comment  from t order by id ;
+----+--------------+-------------------+--------+--------------+--------------------+-------------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data   | hex(data)    | hex(&amp;apos;小明&amp;apos;)      | comment                       |
+----+--------------+-------------------+--------+--------------+--------------------+-------------------------------+
|  1 |            6 |                 3 | 小明    | E5B08FE6988E | E7818FE5BF94E6A791 | 3 gbk                         |
|  2 |            4 |                 2 | С      | D0A1C3F7     | E7818FE5BF94E6A791 | character_set_client utf8     |
|  3 |            6 |                 3 | 小明    | E5B08FE6988E | E7818FE5BF94E6A791 | character_set_connection utf8 |
+----+--------------+-------------------+--------+--------------+--------------------+-------------------------------+
3 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;SecureCRT(utf8 E5B08FE6988E)–&amp;gt; character_set_client(gbk E5B08FE6988E)–&amp;gt;character_set_connection(utf8 E5B08FE6988E)–&amp;gt;database(gbk E5B08FE6988E)–&amp;gt;character_set_results(gbk E5B08FE6988E)–&amp;gt;SecureCRT(utf8 E5B08FE6988E)&lt;/p&gt;
&lt;p&gt;数据库存储的二进制流E5B08FE6988E不变&lt;br&gt;SecureCRT输入的utf-8字符集‘小明’在这里变成了E7818FE5BF94E6A791&lt;br&gt;client(gbk)–&amp;gt;connection(utf8)未作转化&lt;/p&gt;
&lt;h1 id=&quot;只设置character-set-results为utf8&quot;&gt;&lt;a href=&quot;#只设置character-set-results为utf8&quot; class=&quot;headerlink&quot; title=&quot;只设置character_set_results为utf8&quot;&gt;&lt;/a&gt;只设置character_set_results为utf8&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;set names gbk;
Query OK, 0 rows affected (0.00 sec)

set character_set_results=utf8;
Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | gbk                               |
| character_set_connection | gbk                               |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | utf8                              |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

insert into T values(null,&amp;apos;小明&amp;apos;,&amp;apos;character_set_results utf8&amp;apos;);          
Query OK, 1 row affected (0.00 sec)

guo@ha 12:27:06&amp;gt;SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),hex(&amp;apos;小明&amp;apos;),comment  from t order by id ;
+----+--------------+-------------------+-----------+--------------+------------------+-------------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data      | hex(data)    | hex(&amp;apos;灏忔槑&amp;apos;) | comment                       |
+----+--------------+-------------------+-----------+--------------+------------------+-------------------------------+
|  1 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E     | 3 gbk                         |
|  2 |            4 |                 2 | 小明    | D0A1C3F7     | E5B08FE6988E     | character_set_client utf8     |
|  3 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E     | character_set_connection utf8 |
|  4 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E     | character_set_results utf8    |
+----+--------------+-------------------+-----------+--------------+------------------+-------------------------------+
4 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;SecureCRT(utf8 E5B08FE6988E)–&amp;gt; character_set_client(gbk E5B08FE6988E)–&amp;gt;character_set_connection(gbk E5B08FE6988E)–&amp;gt;database(gbk E5B08FE6988E)–&amp;gt;character_set_results(utf8 E7818FE5BF94E6A791 灏忔槑)–&amp;gt;SecureCRT(utf8 E7818FE5BF94E6A791 灏忔槑)&lt;br&gt;client(gbk)–&amp;gt;connection(gbk)未作转化&lt;/p&gt;
&lt;p&gt;这里只是显示出了问题，数据库存储的二进制流E5B08FE6988E不变，gbk存储的“小明”也能正常显示&lt;br&gt;SecureCRT输入的utf-8字符集‘小明’在这里也是E5B08FE6988E，但是“小明”显示成了“灏忔槑”对应二进制流E7818FE5BF94E6A791，results并没有转换而是直接把E5B08FE6988E当作gbk的字符处理成E7818FE5BF94E6A791&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select unhex(&amp;apos;E7818FE5BF94E6A791&amp;apos;);
+-----------------------------+
| unhex(&amp;apos;E7818FE5BF94E6A791&amp;apos;) |
+-----------------------------+
| 灏忔槑                   |
+-----------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;更改三者为utf8&quot;&gt;&lt;a href=&quot;#更改三者为utf8&quot; class=&quot;headerlink&quot; title=&quot;更改三者为utf8&quot;&gt;&lt;/a&gt;更改三者为utf8&lt;/h1&gt;&lt;p&gt;   改变character_set_client、character_set_connection、character_set_results的设置为utf8，查询插入的值。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set names utf8;
Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;character%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | utf8                              |
| character_set_connection | utf8                              |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | utf8                              |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

 insert into T values(null,&amp;apos;小明&amp;apos;,&amp;apos;3 utf8&amp;apos;);                     
Query OK, 1 row affected (0.00 sec)

guo@ha 12:28:10&amp;gt;SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),hex(&amp;apos;小明&amp;apos;),comment  from t order by id ;
+----+--------------+-------------------+-----------+--------------+---------------+-------------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data      | hex(data)    | hex(&amp;apos;小明&amp;apos;) | comment                       |
+----+--------------+-------------------+-----------+--------------+---------------+-------------------------------+
|  1 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E  | 3 gbk                         |
|  2 |            4 |                 2 | 小明    | D0A1C3F7     | E5B08FE6988E  | character_set_client utf8     |
|  3 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E  | character_set_connection utf8 |
|  4 |            6 |                 3 | 灏忔槑 | E5B08FE6988E | E5B08FE6988E  | character_set_results utf8    |
|  5 |            4 |                 2 | 小明    | D0A1C3F7     | E5B08FE6988E  | 3 utf8                        |
+----+--------------+-------------------+-----------+--------------+---------------+-------------------------------+
5 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;SecureCRT(utf8 E5B08FE6988E)–&amp;gt; character_set_client(utf8 E5B08FE6988E)–&amp;gt;character_set_connection(utf8 E5B08FE6988E)–&amp;gt;database(gbk D0A1C3F7)–&amp;gt;character_set_results(utf8 E5B08FE6988E)–&amp;gt;SecureCRT(utf8 E5B08FE6988E)&lt;/p&gt;
&lt;p&gt; character_set_connection(utf8)–&amp;gt;database(gbk)作了转化&lt;/p&gt;
&lt;p&gt; 综上，MySQL内部二进制流重编码转化条件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只在connection和database阶段进行&lt;/li&gt;
&lt;li&gt;connection、database的前一字符集是当前字符集的超集&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设置SecureCRT的字符集为GBK，看看SecureCRT字符集设置对结果影响&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set names gbk;

Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;%char%&amp;apos;;

+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | gbk                               |
| character_set_connection | gbk                               |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | gbk                               |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),comment  from t order by id ;
+----+--------------+-------------------+--------+----------------+-------------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data   | hex(data)      | comment                       |
+----+--------------+-------------------+--------+----------------+-------------------------------+
|  1 |            6 |                 3 | 灏忔槑 | E5B08FE6988E    | 3 gbk                         |
|  2 |            4 |                 2 | 小明   | D0A1C3F7       | character_set_client utf8     |
|  3 |            6 |                 3 | 灏忔槑 | E5B08FE6988E   | character_set_connection utf8 |
|  4 |            6 |                 3 | 灏忔槑 | E5B08FE6988E   | character_set_results utf8    |
|  5 |            4 |                 2 | 小明   | D0A1C3F7       | 3 utf8                        |
+----+--------------+-------------------+--------+----------------+-------------------------------+
5 rows in set (0.00 sec)

set  names utf8;

Query OK, 0 rows affected (0.00 sec)

show variables like &amp;apos;%char%&amp;apos;;
+--------------------------+-----------------------------------+
| Variable_name            | Value                             |
+--------------------------+-----------------------------------+
| character_set_client     | utf8                              |
| character_set_connection | utf8                              |
| character_set_database   | gbk                               |
| character_set_filesystem | binary                            |
| character_set_results    | utf8                              |
| character_set_server     | utf8mb4                           |
| character_set_system     | utf8                              |
| character_sets_dir       | /home/mysql/mysql/share/charsets/ |
+--------------------------+-----------------------------------+
8 rows in set (0.00 sec)

SELECT id,LENGTH(data), CHAR_LENGTH(data),data,hex(data),comment  from t order by id ;
+----+--------------+-------------------+-----------+--------------+-------------------------------+
| id | LENGTH(data) | CHAR_LENGTH(data) | data      | hex(data)    | comment                       |
+----+--------------+-------------------+-----------+--------------+-------------------------------+
|  1 |            6 |                 3 | 鐏忓繑妲    B08FE6988E    | 3 gbk                         |
|  2 |            4 |                 2 | 灏忔槑     |D0A1C3F7     | character_set_client utf8     |
|  3 |            6 |                 3 | 鐏忓繑妲    B08FE6988E    | character_set_connection utf8 |
|  4 |            6 |                 3 | 鐏忓繑妲    B08FE6988E    | character_set_results utf8    |
|  5 |            4 |                 2 | 灏忔槑     | D0A1C3F7     | 3 utf8                        |
+----+--------------+-------------------+-----------+--------------+-------------------------------+
5 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;相关阅读&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/cchust/p/4327019.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/cchust/p/4327019.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;我们知道set names utf8;改变的character_set_client、character_set_connection、character_set_result三个值，MySQL字符集的内部转换到底是哪个阶段呢，下面通过控制变量法来验证。&lt;/p&gt;

    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="字符集" scheme="http://idber.github.io/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>计算机原理之编码</title>
    <link href="http://idber.github.io/2019/05/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E7%BC%96%E7%A0%81.html"/>
    <id>http://idber.github.io/2019/05/11-计算机原理之编码.html</id>
    <published>2019-05-11T02:01:56.000Z</published>
    <updated>2019-05-11T09:19:52.154Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;编码与加密&quot;&gt;&lt;a href=&quot;#编码与加密&quot; class=&quot;headerlink&quot; title=&quot;编码与加密&quot;&gt;&lt;/a&gt;编码与加密&lt;/h1&gt;&lt;h2 id=&quot;加密&quot;&gt;&lt;a href=&quot;#加密&quot; class=&quot;headerlink&quot; title=&quot;加密&quot;&gt;&lt;/a&gt;加密&lt;/h2&gt;&lt;p&gt;什么是编码？他与加密有什么区别？&lt;br&gt;在密码学中，加密（英语：Encryption）是将明文信息改变为难以读取的密文内容，使之不可读的过程。只有拥有解密方法的对象，经由解密过程，才能将密文还原为正常可读的内容。&lt;/p&gt;
&lt;h2 id=&quot;编码&quot;&gt;&lt;a href=&quot;#编码&quot; class=&quot;headerlink&quot; title=&quot;编码&quot;&gt;&lt;/a&gt;编码&lt;/h2&gt;&lt;p&gt;那么什么是编码呢？&lt;br&gt;编码（Encoding）在认知上是解释传入的刺激的一种基本知觉的过程。技术上来说，这是一个复杂的、多阶段的转换过程，从较为客观的感觉输入（例如光、声）到主观上有意义的体验，是信息从一种形式或格式转换为另一种形式的过程。&lt;br&gt;解码，是编码的逆过程。&lt;/p&gt;
&lt;h2 id=&quot;加密与编码的关系&quot;&gt;&lt;a href=&quot;#加密与编码的关系&quot; class=&quot;headerlink&quot; title=&quot;加密与编码的关系&quot;&gt;&lt;/a&gt;加密与编码的关系&lt;/h2&gt;&lt;p&gt;从概念上可以看出，编码只是表现形式的转换，没有保密的作用，因为编码和解码的算法是公开的，只要知道是什么编码的内容，任何人都可以轻松地解码。从这个角度看加密也一种编码，只是解密算法是非公开的。&lt;/p&gt;
&lt;h1 id=&quot;字符编码&quot;&gt;&lt;a href=&quot;#字符编码&quot; class=&quot;headerlink&quot; title=&quot;字符编码&quot;&gt;&lt;/a&gt;字符编码&lt;/h1&gt;&lt;p&gt;字符编码（英语：Character encoding）、字集码是把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。常见的例子包括将拉丁字母表编码成摩斯电码和ASCII。其中，ASCII将字母、数字和其它符号编号，并用7比特的二进制来表示这个整数。通常会额外使用一个扩充的比特，以便于以1个字节的方式存储。&lt;/p&gt;
&lt;p&gt;在计算机技术发展的早期，如ASCII（1963年）和EBCDIC（1964年）这样的字符集逐渐成为标准。但这些字符集的局限很快就变得明显，于是人们开发了许多方法来扩展它们。对于支持包括东亚CJK字符家族在内的写作系统的要求能支持更大量的字符，并且需要一种系统而不是临时的方法实现这些字符的编码。&lt;/p&gt;
&lt;p&gt;为了弄懂计算机是怎么实现编码的，就要先理解计算机如何存储数据的。&lt;/p&gt;
&lt;h1 id=&quot;数据在计算机中的存储&quot;&gt;&lt;a href=&quot;#数据在计算机中的存储&quot; class=&quot;headerlink&quot; title=&quot;数据在计算机中的存储&quot;&gt;&lt;/a&gt;数据在计算机中的存储&lt;/h1&gt;&lt;p&gt;我们知道数据在计算机中是以二进制的形式存储的，那么有没有想过01这些数据是怎么存在计算机当中的呢？&lt;/p&gt;
&lt;h2 id=&quot;第一步-如何存储0和1&quot;&gt;&lt;a href=&quot;#第一步-如何存储0和1&quot; class=&quot;headerlink&quot; title=&quot;第一步 如何存储0和1&quot;&gt;&lt;/a&gt;第一步 如何存储0和1&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/charset000%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A80%E5%92%8C1.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;不知道你们有没有听过一个东西，叫做——电容器。顾名思义，这是一种能容纳电荷的容器。与普通的电池不同的是，它的充电速度很快，并且因为不会转化为化学能所以电量流失的也很快。因此需要经常刷新。在我们的计算机中，CPU有一个参数是Hz，便是指每秒钟能充多少次电。数据在内存中以二进制的方式存储，事实上是通过对小电容器的充放电来完成的。 &lt;/p&gt;
&lt;h2 id=&quot;第二步-如何存储数字&quot;&gt;&lt;a href=&quot;#第二步-如何存储数字&quot; class=&quot;headerlink&quot; title=&quot;第二步 如何存储数字&quot;&gt;&lt;/a&gt;第二步 如何存储数字&lt;/h2&gt;&lt;p&gt;当然是把数字转化成二进制啦&lt;/p&gt;
&lt;h2 id=&quot;第三步-如何存储字符&quot;&gt;&lt;a href=&quot;#第三步-如何存储字符&quot; class=&quot;headerlink&quot; title=&quot;第三步 如何存储字符&quot;&gt;&lt;/a&gt;第三步 如何存储字符&lt;/h2&gt;&lt;p&gt;既然能够存储0和1，那存储字符也就不是什么难事了吧。我们只需要把字符和二进制一一对应起来，然后责令计算机来记住它，就万事大吉了。ASCII美国信息交换标准码就是干这件事。&lt;/p&gt;
&lt;h2 id=&quot;第四步-如何存储汉字&quot;&gt;&lt;a href=&quot;#第四步-如何存储汉字&quot; class=&quot;headerlink&quot; title=&quot;第四步 如何存储汉字&quot;&gt;&lt;/a&gt;第四步 如何存储汉字&lt;/h2&gt;&lt;p&gt;当然，早期的时候计算机并没有在中国兴起，所以中文并不能被计算机所识别，直到1980年GB2312（信息交换用汉字编码字符集）横空出世。功能与ASCII相似。当然，后来又有了GBK（国际标准扩展），我们暂且不提。 &lt;/p&gt;
&lt;h2 id=&quot;第五步-如何存储所有字符&quot;&gt;&lt;a href=&quot;#第五步-如何存储所有字符&quot; class=&quot;headerlink&quot; title=&quot;第五步 如何存储所有字符&quot;&gt;&lt;/a&gt;第五步 如何存储所有字符&lt;/h2&gt;&lt;p&gt;照葫芦画瓢，将所有的字符进行编号，所以有了Unicode字符集。但是这里有一个问题，虽然它可以存储世界上所有的字符，但是如果你的编码是000000000000001，它是不会自动给你简化成1的。由此直接导致了所有的文字存储代价都会翻倍，而这样的代价，是很多人都不愿意看见的。&lt;/p&gt;
&lt;h2 id=&quot;第六步-如何将Unicode存到计算机里&quot;&gt;&lt;a href=&quot;#第六步-如何将Unicode存到计算机里&quot; class=&quot;headerlink&quot; title=&quot;第六步 如何将Unicode存到计算机里&quot;&gt;&lt;/a&gt;第六步 如何将Unicode存到计算机里&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/charset005%E7%AC%AC%E5%85%AD%E6%AD%A5%E5%A6%82%E4%BD%95%E5%B0%86Unicode%E5%AD%98%E5%88%B0%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%87%8C.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里稍微解释一下最后一行，第一块的两个11是指后边有两串跟着，紧接着的10是指两串开头两个标志位是10。上边的Unicode编码中截取后两个字节放到下边utf-8中除标志位之外的地方，也就是说，除了第一块开头的1110，第二块和第三块开头的10，我们有4+6+6=16位来依次存储上边的8+8=16位字符串。&lt;br&gt;如你所见，这就是UTF-8，一种编码方式。它采用了变长存储的形式来表示Unicode字符集。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/charset003UTF8.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;编码与加密&quot;&gt;&lt;a href=&quot;#编码与加密&quot; class=&quot;headerlink&quot; title=&quot;编码与加密&quot;&gt;&lt;/a&gt;编码与加密&lt;/h1&gt;&lt;h2 id=&quot;加密&quot;&gt;&lt;a href=&quot;#加密&quot; class=&quot;headerlink&quot; title=&quot;加密&quot;&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="计算机原理" scheme="http://idber.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
      <category term="编码" scheme="http://idber.github.io/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的伪utf8字符集</title>
    <link href="http://idber.github.io/2019/05/10-MySQL%E7%9A%84%E4%BC%AAutf8%E5%AD%97%E7%AC%A6%E9%9B%86.html"/>
    <id>http://idber.github.io/2019/05/10-MySQL的伪utf8字符集.html</id>
    <published>2019-05-10T02:01:56.000Z</published>
    <updated>2019-05-13T10:05:40.032Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;标准UTF-8字符集&quot;&gt;&lt;a href=&quot;#标准UTF-8字符集&quot; class=&quot;headerlink&quot; title=&quot;标准UTF-8字符集&quot;&gt;&lt;/a&gt;标准UTF-8字符集&lt;/h1&gt;&lt;p&gt;UTF-8（8-bit Unicode Transformation Format）即8位Unicode转换格式，是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或发送文字优先采用的编码。&lt;/p&gt;
&lt;p&gt;UTF-8使用一至六个字节为每个字符编码（尽管如此，2003年11月UTF-8被RFC 3629重新规范，只能使用原来Unicode定义的区域，U+0000到U+10FFFF，也就是说最多&lt;font color=&quot;red&quot;&gt;四个字节&lt;/font&gt;）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;128个US-ASCII字符只需一个字节编码（Unicode范围由U+0000至U+007F）。&lt;/li&gt;
&lt;li&gt;带有附加符号的拉丁文、希腊文、西里尔字母、亚美尼亚语、希伯来文、阿拉伯文、叙利亚文及它拿字母则需要两个字节编码（Unicode范围由U+0080至U+07FF）。&lt;/li&gt;
&lt;li&gt;其他基本多文种平面（BMP）中的字符（这包含了大部分常用字，如大部分的汉字）使用三个字节编码（Unicode范围由U+0800至U+FFFF）。&lt;/li&gt;
&lt;li&gt;其他极少使用的Unicode 辅助平面的字符使用四至六字节编码（Unicode范围由U+10000至U+1FFFFF使用四字节，Unicode范围由U+200000至U+3FFFFFF使用五字节，Unicode范围由U+4000000至U+7FFFFFFF使用六字节）。&lt;br&gt;对上述提及的第四种字符而言，UTF-8使用四至六个字节来编码似乎太耗费资源了。但UTF-8对所有常用的字符都可以用三个字节表示，而且它的另一种选择，UTF-16编码，对前述的第四种字符同样需要四个字节来编码，所以要决定UTF-8或UTF-16哪种编码比较有效率，还要视所使用的字符的分布范围而定。不过，如果使用一些传统的压缩系统，比如DEFLATE，则这些不同编码系统间的的差异就变得微不足道了。若顾及传统压缩算法在压缩较短文字上的效果不大，可以考虑使用Unicode标准压缩格式（SCSU）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;互联网工程工作小组（IETF）要求所有互联网协议都必须支持UTF-8编码。互联网邮件联盟（IMC）建议所有电子邮件软件都支持UTF-8编码。&lt;/p&gt;
&lt;h1 id=&quot;MySQL的utf8&quot;&gt;&lt;a href=&quot;#MySQL的utf8&quot; class=&quot;headerlink&quot; title=&quot;MySQL的utf8&quot;&gt;&lt;/a&gt;MySQL的utf8&lt;/h1&gt;&lt;p&gt;官方手册 &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-sets.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-sets.html&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;utf8mb4: A UTF-8 encoding of the Unicode character set using one to four bytes per character.&lt;/p&gt;
&lt;p&gt;utf8mb3: A UTF-8 encoding of the Unicode character set using one to three bytes per character.&lt;/p&gt;
&lt;p&gt;utf8: An alias for utf8mb3.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-conversion.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-conversion.html&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;utf8mb3 supports only characters in the Basic Multilingual Plane (BMP). utf8mb4 additionally supports supplementary characters that lie outside the BMP.&lt;/p&gt;
&lt;p&gt;utf8mb3 uses a maximum of three bytes per character. utf8mb4 uses a maximum of four bytes per character.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从手册中可以看到，utf8实际上是utf8mb3的别名，即maximum of three bytes per character最大只支持3个字节，MySQL官方并未直接修复这个问题，而是在5.5.3之后增加了utf8mb4字符编码，mb4即 maximum of four bytes。简单说 utf8mb4 是 utf8 的超集并完全兼容utf8，能够用四个字节存储更多的字符。&lt;/p&gt;
&lt;p&gt;但抛开数据库，标准的 UTF-8 字符集编码是可以用 1~4 个字节去编码21位字符，这几乎包含了是世界上所有能看见的语言了。然而在MySQL里实现的utf8最长使用3个字节，也就是上面提到的标准UTF-8中“基本多文种平面（BMP）中的字符（这包含了大部分常用字，如大部分的汉字）使用三个字节编码（Unicode范围由U+0800至U+FFFF）。”但并不是所有，最常见的就算现在手机端常用的表情字符emoji，需要四个字节（Unicode范围由U+10000至U+1FFFFF）才能编码出来。&lt;/p&gt;
&lt;p&gt;注：QQ里面的内置的表情不算，它是通过特殊映射到的一个gif图片。一般输入法自带的才是emoji。&lt;/p&gt;
&lt;p&gt;也就是当你的数据库里要求能够存入这些表情或宽字符时，可以把字段定义为 utf8mb4，同时要注意连接字符集也要设置为utf8mb4，否则在 严格模式 下会出现 Incorrect string value: \xF0\x9F\x98\x84… for column ‘content’这样的错误，非严格模式下此后的数据会被截断。&lt;/p&gt;
&lt;p&gt;关于网上流传的latin1也支持emoji，&lt;a href=&quot;https://stackoverflow.com/questions/30187853/does-mysql-latin1-also-support-emoji-character&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Does mysql latin1 also support emoji character?&lt;/a&gt;。&lt;br&gt;这里有一个问题就是，输入源要支持标准的UTF-8，操作系统的字符集为utf8（LANG=en_US.UTF-8）目前大部分系统都支持, 而client、connection、database均为latin1, 于是这一路（从终端界面执行insert到保存数据到表中）都没有编码转换，直接传输的是utf8编码后的二进制流。&lt;br&gt;latin1字符集的表，用户写入和读取汉字、emoji是否有问题？答案是只要设置合理，是没有问题的。假设SecureCRT为UTF8，character_set_client和表字符集均设置为latin1，那么用户读取和写入数据的过程中，并不涉及字符集编码转换的过程，将UTF8的汉字或emoji字符转为二进制流写入database，提取出来后，secureCRT再将对应的二进制解码为对应的汉字或emoji，所以不影响用户的使用。&lt;/p&gt;
&lt;p&gt;，&lt;br&gt;&lt;!--以下为引用 [via](http://seanlook.com/2016/10/23/mysql-utf8mb4/)
--&gt;&lt;/p&gt;
&lt;h1 id=&quot;utf8-unicode-ci和utf8-general-ci区别&quot;&gt;&lt;a href=&quot;#utf8-unicode-ci和utf8-general-ci区别&quot; class=&quot;headerlink&quot; title=&quot;utf8_unicode_ci和utf8_general_ci区别&quot;&gt;&lt;/a&gt;utf8_unicode_ci和utf8_general_ci区别&lt;/h1&gt;&lt;p&gt;字符除了需要存储，还需要排序或比较大小，涉及到与编码字符集对应的排序字符集（collation）。ut8mb4对应的排序字符集常用的有 utf8mb4_unicode_ci、utf8mb4_general_ci，到底采用哪个在 stackoverflow 上有个讨论，&lt;a href=&quot;http://stackoverflow.com/questions/766809/whats-the-difference-between-utf8-general-ci-and-utf8-unicode-ci&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;What’s the difference between utf8_general_ci and utf8_unicode_ci&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在数据库系统MySQL或MariaDB中有多种字符集，其中utf8_unicode_ci和utf8_general_ci是最常用的，但是utf8_general_ci对某些语言的支持有一些小问题，如果可以接受，那最好使用utf8_general_ci，因为它速度快。否则，请使用较为精确的utf8_unicode_ci，不过速度会慢一些。&lt;/p&gt;
&lt;h1 id=&quot;怎么从utf8转换为utf8mb4&quot;&gt;&lt;a href=&quot;#怎么从utf8转换为utf8mb4&quot; class=&quot;headerlink&quot; title=&quot;怎么从utf8转换为utf8mb4&quot;&gt;&lt;/a&gt;怎么从utf8转换为utf8mb4&lt;/h1&gt;&lt;h2 id=&quot;“伪”转换&quot;&gt;&lt;a href=&quot;#“伪”转换&quot; class=&quot;headerlink&quot; title=&quot;“伪”转换&quot;&gt;&lt;/a&gt;“伪”转换&lt;/h2&gt;&lt;p&gt;如果你的表定义和连接字符集都是utf8，那么直接在你的表上执行&lt;/p&gt;
&lt;p&gt;ALTER TABLE tbl_name CONVERT TO CHARACTER SET utf8mb4;&lt;br&gt;则能够该表上所有的列的character类型变成 utf8mb4，表定义的默认字符集也会修改。连接的时候需要使用set names utf8mb4便可以插入四字节字符。（如果依然使用 utf8 连接，只要不出现四字节字符则完全没问题）。&lt;/p&gt;
&lt;p&gt;上面的 convert 有两个问题，一是它不能ONLINE，也就是执行之后全表禁止修改，有关这方面的讨论见 mysql 5.6 原生Online DDL解析；二是，它可能会自动该表字段类型定义，如 VARCHAR 被转成 MEDIUMTEXT，可以通过 MODIFY 指定类型为原类型。&lt;/p&gt;
&lt;p&gt;另外 ALTER TABLE tbl_name DEFAULT CHARACTER SET utf8mb4 这样的语句就不要随便执行了，特别是当表原本不是utf8时，除非表是空的或者你确认表里只有拉丁字符，否则正常和乱的就混在一起了。&lt;/p&gt;
&lt;p&gt;最重要的是，你连接时使用的latin1字符集写入了历史数据，表定义是latin1或utf8，不要期望通过 ALTER … CONVERT … 能够让你达到用utf8读取历史中文数据的目的，没卵用，老老实实做逻辑dump。所以我才叫它“伪”转换&lt;/p&gt;
&lt;h2 id=&quot;character-set-server&quot;&gt;&lt;a href=&quot;#character-set-server&quot; class=&quot;headerlink&quot; title=&quot;character-set-server&quot;&gt;&lt;/a&gt;character-set-server&lt;/h2&gt;&lt;p&gt;一旦你决定使用utf8mb4，强烈建议你要修改服务端 character-set-server=utf8mb4，不同的语言对它的处理方法不一样，c++, php, python可以设置character-set，但java驱动依赖于 character-set-server 选项，后面有介绍。&lt;/p&gt;
&lt;p&gt;同时还要谨慎一些特殊选项，个人不建议设置全局 init_connect。&lt;/p&gt;
&lt;h1 id=&quot;key-767-bytes-错误&quot;&gt;&lt;a href=&quot;#key-767-bytes-错误&quot; class=&quot;headerlink&quot; title=&quot;key 767 bytes 错误&quot;&gt;&lt;/a&gt;key 767 bytes 错误&lt;/h1&gt;&lt;p&gt;字符集从utf8转到utf8mb4之后，最容易引起的就是索引键超长的问题。&lt;/p&gt;
&lt;p&gt;对于表行格式是 COMPACT或 REDUNDANT，InnoDB有单个索引最大字节数 768 的限制，而字段定义的是能存储的字符数，比如 VARCHAR(200) 代表能够存200个汉字，索引定义是字符集类型最大长度算的，即 utf8 maxbytes=3, utf8mb4 maxbytes=4，算下来utf8和utf8mb4两种情况的索引长度分别为600 bytes和800bytes，后者超过了767，导致出错：Error 1071: Specified key was too long; max key length is 767 bytes。&lt;/p&gt;
&lt;p&gt;COMPRESSED和DYNAMIC格式不受限制，但也依然不建议索引太长，太浪费空间和cpu搜索资源。&lt;/p&gt;
&lt;p&gt;如果已有定义超过这个长度的，可加上前缀索引，如果暂不能加上前缀索引（像唯一索引），可把该字段的字符集改回utf8或latin1。&lt;br&gt;但是，（ 敲黑板啦，很重要 ），要防止出现 Illegal mix of collations (utf8_general_ci,IMPLICIT) and (utf8mb4_general_ci,COERCIBLE) for operation ‘=’ 错误：连接字符集使用utf8mb4，但 SELECT/UPDATE where条件有utf8类型的列，且条件右边存在不属于utf8字符，就会触发该异常。表示踩过这个坑。&lt;/p&gt;
&lt;p&gt;再多加一个友好提示：EXPLAIN 结果里面的 key_len 指的搜索索引长度，单位是bytes，而且是以字符集支持的单字符最大字节数算的，这也是为什么 INDEX_LENGTH 膨胀厉害的一个原因。&lt;/p&gt;
&lt;h1 id=&quot;C-C-内存空间分配问题&quot;&gt;&lt;a href=&quot;#C-C-内存空间分配问题&quot; class=&quot;headerlink&quot; title=&quot;C/C++ 内存空间分配问题&quot;&gt;&lt;/a&gt;C/C++ 内存空间分配问题&lt;/h1&gt;&lt;p&gt;这是我们这边的开发遇到的一个棘手的问题。C或C++连接MySQL使用的是linux系统上的 libmysqlclient 动态库，程序获取到数据之后根据自定义的一个网络协议，按照mysql字段定义的固定字节数来传输数据。从utf8转utf8mb4之后，c++里面针对character单字符内存空间分配，从3个增加到4个，引起异常。&lt;/p&gt;
&lt;p&gt;这个问题其实是想说明，使用utf8mb4之后，官方建议尽量用 varchar 代替 char，这样可以减少固定存储空间浪费（关于char与varchar的选择，可参考 这里）。但开发设计表时 varchar 的大小不能随意加大，它虽然是变长的，但客户端在定义变量来获取数据时，是以定义的为准，而非实际长度。按需分配，避免程序使用过多的内存。&lt;/p&gt;
&lt;h1 id=&quot;java驱动使用&quot;&gt;&lt;a href=&quot;#java驱动使用&quot; class=&quot;headerlink&quot; title=&quot;java驱动使用&quot;&gt;&lt;/a&gt;java驱动使用&lt;/h1&gt;&lt;p&gt;Java语言里面所实现的UTF-8编码就是支持4字节的，所以不需要配置 mb4 这样的字眼，但如果从MySQL读写emoji，MySQL驱动版本要在 5.1.13 及以上版本，数据库连接依然是 characterEncoding=UTF-8 。&lt;/p&gt;
&lt;p&gt;但还没完，遇到一个大坑。官方手册 里还有这么一段话：&lt;/p&gt;
&lt;p&gt;Connector/J did not support utf8mb4 for servers 5.5.2 and newer.&lt;/p&gt;
&lt;p&gt;Connector/J now auto-detects servers configured with character_set_server=utf8mb4 or treats the Java encoding utf-8 passed&lt;br&gt;  using characterEncoding=… as utf8mb4 in the SET NAMES= calls it makes when establishing the connection. (Bug #54175)&lt;br&gt;意思是，java驱动会自动检测服务端 character_set_server 的配置，如果为utf8mb4，驱动在建立连接的时候设置 SET NAMES utf8mb4。然而其他语言没有依赖于这样的特性。&lt;/p&gt;
&lt;h1 id=&quot;主从复制报错&quot;&gt;&lt;a href=&quot;#主从复制报错&quot; class=&quot;headerlink&quot; title=&quot;主从复制报错&quot;&gt;&lt;/a&gt;主从复制报错&lt;/h1&gt;&lt;p&gt;这个问题没有遇到，只是看官方文档有提到，曾经也看到过类似的技术文章。&lt;br&gt;大概就是从库的版本比主库的版本低，导致有些字符集不支持；或者人工修改了从库上的表或字段的字符集定义，都有可能引起异常。&lt;/p&gt;
&lt;h1 id=&quot;join-查询问题&quot;&gt;&lt;a href=&quot;#join-查询问题&quot; class=&quot;headerlink&quot; title=&quot;join 查询问题&quot;&gt;&lt;/a&gt;join 查询问题&lt;/h1&gt;&lt;p&gt;这个问题是之前在姜承尧老师公众号看到的一篇文章 MySQL表字段字符集不同导致的索引失效问题，自己也验证了一下，的确会有问题：&lt;/p&gt;
&lt;p&gt;CREATE TABLE t1 (&lt;br&gt;  f_id varchar(20) NOT NULL,&lt;br&gt;  f_action char(25) NOT NULL DEFAULT ‘’ COMMENT ‘’,&lt;br&gt;  PRIMARY KEY (&lt;code&gt;f_id&lt;/code&gt;),&lt;br&gt;) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;&lt;/p&gt;
&lt;p&gt;CREATE TABLE t1_copy_mb4 (&lt;br&gt;  f_id varchar(20) CHARACTER SET utf8mb4 NOT NULL,&lt;br&gt;  f_action char(25) NOT NULL DEFAULT ‘’ COMMENT ‘’,&lt;br&gt;  PRIMARY KEY (&lt;code&gt;f_id&lt;/code&gt;),&lt;br&gt;) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;&lt;/p&gt;
&lt;p&gt;1.&lt;br&gt;EXPLAIN extended select * from t1 INNER JOIN t1_copy_mb4 t2 on t1.f_id=t2.f_id where t1.f_id=’421036’;&lt;/p&gt;
&lt;p&gt;2.&lt;br&gt;EXPLAIN extended select * from t1 INNER JOIN t1_copy_mb4 t2 on t1.f_id=t2.f_id where t2.f_id=’421036’;&lt;br&gt;对应上面1,2 的截图：&lt;/p&gt;
&lt;p&gt;其中 2 的warnings 有convert:&lt;/p&gt;
&lt;p&gt;(convert(t1.f_id using utf8mb4) = ‘421036’)&lt;br&gt;官网能找到这一点解释的还是开头那个地址：&lt;/p&gt;
&lt;p&gt;Similarly, the following comparison in the WHERE clause works according to the collation of utf8mb4_col:&lt;/p&gt;
&lt;p&gt;  SELECT * FROM utf8_tbl, utf8mb4_tbl&lt;br&gt;  WHERE utf8_tbl.utf8_col = utf8mb4_tbl.utf8mb4_col;&lt;br&gt;只是索引失效发生在utf8mb4列 在条件左边。（关于MySQL的隐式类型转换，见这里）。&lt;/p&gt;
&lt;p&gt;参考&lt;br&gt;&lt;a href=&quot;https://my.oschina.net/zhuguowei/blog/414476&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mysql latin1也支持emoji字符的错觉分析&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/cchust/p/4327019.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mysql字符集知识总结&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/charset-unicode-conversion.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/doc/refman/8.0/en/charset-unicode-conversion.html&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://forums.mysql.com/read.php?103,187048,188748#msg-188748&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://forums.mysql.com/read.php?103,187048,188748#msg-188748&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://drupal.stackexchange.com/questions/166405/why-are-we-using-utf8mb4-general-ci-and-not-utf8mb4-unicode-ci&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Why are we using utf8mb4_general_ci and not utf8mb4_unicode_ci?&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://mathiasbynens.be/notes/mysql-utf8mb4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;How to support full Unicode in MySQL databases&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cenalulu.github.io/mysql/mysql-mojibake/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;10分钟学会理解和解决MySQL乱码问题&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;标准UTF-8字符集&quot;&gt;&lt;a href=&quot;#标准UTF-8字符集&quot; class=&quot;headerlink&quot; title=&quot;标准UTF-8字符集&quot;&gt;&lt;/a&gt;标准UTF-8字符集&lt;/h1&gt;&lt;p&gt;UTF-8（8-bit Unicode Transformatio
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="字符集" scheme="http://idber.github.io/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>在Mac上使用CLion编译MySQL</title>
    <link href="http://idber.github.io/2019/05/09-%E5%9C%A8Mac%E4%B8%8A%E4%BD%BF%E7%94%A8CLion%E7%BC%96%E8%AF%91MySQL.html"/>
    <id>http://idber.github.io/2019/05/09-在Mac上使用CLion编译MySQL.html</id>
    <published>2019-05-09T02:01:56.000Z</published>
    <updated>2019-05-09T07:29:18.693Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;源码获取&quot;&gt;&lt;a href=&quot;#源码获取&quot; class=&quot;headerlink&quot; title=&quot;源码获取&quot;&gt;&lt;/a&gt;源码获取&lt;/h1&gt;&lt;p&gt;git clone &lt;a href=&quot;https://github.com/mysql/mysql-server&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/mysql/mysql-server&lt;/a&gt;&lt;br&gt;or&lt;br&gt;&lt;a href=&quot;https://dev.mysql.com/downloads/mysql/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/downloads/mysql/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;解压&lt;br&gt;mysql-server 为源码目录&lt;br&gt;新建mysql、data目录&lt;br&gt;mysql为basedir&lt;br&gt;data为datadir&lt;/p&gt;
&lt;h1 id=&quot;编译安装初始化数据库&quot;&gt;&lt;a href=&quot;#编译安装初始化数据库&quot; class=&quot;headerlink&quot; title=&quot;编译安装初始化数据库&quot;&gt;&lt;/a&gt;编译安装初始化数据库&lt;/h1&gt;&lt;p&gt;cd mysql-server&lt;/p&gt;
&lt;p&gt;cmake \&lt;br&gt;-DCMAKE_INSTALL_PREFIX=/your_path/mysql \&lt;br&gt;-DMYSQL_DATADIR=/your_path/mysql/data \&lt;br&gt;-DSYSCONFDIR=/your_path/mysql \&lt;br&gt;-DMYSQL_UNIX_ADDR=/your_path/mysql/mysql.sock \&lt;br&gt;-DWITH_DEBUG=1  \&lt;br&gt;-DDOWNLOAD_BOOST=1 -DWITH_BOOST=/your_path/mysql-server/ -DDOWNLOAD_BOOST_TIMEOUT=60000&lt;/p&gt;
&lt;p&gt;make -j 4 &lt;/p&gt;
&lt;p&gt;make install -j 4&lt;/p&gt;
&lt;h1 id=&quot;初始化数据库&quot;&gt;&lt;a href=&quot;#初始化数据库&quot; class=&quot;headerlink&quot; title=&quot;初始化数据库&quot;&gt;&lt;/a&gt;初始化数据库&lt;/h1&gt;&lt;p&gt;/your_path/mysql/scripts/mysql_install_db –user=mysql –basedir=/your_path/mysql –datadir=/Users/xmzj/SourceCode/mysql/data&lt;br&gt;不同版本数据库有不同初始化方式，本文使用的是MySQL 5.6&lt;/p&gt;
&lt;p&gt;启动MySQL，测试下是否安装成功&lt;/p&gt;
&lt;p&gt;/path/mysql/bin/mysqld –defaults-file=/path/mysql/my.cnf&lt;/p&gt;
&lt;p&gt;在CLion欢迎页选择New CMake Project from Sources,选中CMakeLists.txt，Open Existing Project&lt;br&gt;CLion会自动Load工程&lt;br&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code01.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;br&gt;然后，CLion 偏好设置，Build, Execution, Deployment 的CMake选项&lt;br&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code02.jpeg?raw=true&quot; alt=&quot;&quot;&gt;&lt;br&gt;CMake Options和你编译安装时的选项一致&lt;/p&gt;
&lt;p&gt;-DCMAKE_INSTALL_PREFIX=/path/mysql&lt;br&gt;-DMYSQL_DATADIR=/path/mysql/data&lt;br&gt;-DSYSCONFDIR=/path/mysql&lt;br&gt;-DMYSQL_UNIX_ADDR=/path/mysql/mysql.sock&lt;br&gt;-DWITH_DEBUG=1  &lt;/p&gt;
&lt;p&gt;然后在CLion里，Reload CMake Project&lt;br&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code03.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在Run/Debug列表里就可以看到很多选项了 Edit Configurations…&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code04.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;br&gt;找到mysqld配置下启动参数 mysqld配置下启动参数&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code05.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;mysqld –defaults-file=/path/mysql/etc/my.cnf&lt;br&gt;然后以Debug模式启动，看下成功的效果 Debug模式启动&lt;br&gt;这里故意把ib_qry_type_t改为0ib_qry_type_t 让它报错&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idber/idber.photo/blob/master/blog/source_code/source_code06.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;学习MySQL源码的文档&quot;&gt;&lt;a href=&quot;#学习MySQL源码的文档&quot; class=&quot;headerlink&quot; title=&quot;学习MySQL源码的文档&quot;&gt;&lt;/a&gt;学习MySQL源码的文档&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/doc/internals/en/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/doc/internals/en/&lt;/a&gt;&lt;br&gt;可以找到想要学习的功能的源码位置，比如主从同步功能（replication） &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/doc/internals/en/replication-source-code-files.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dev.mysql.com/doc/internals/en/replication-source-code-files.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;源码获取&quot;&gt;&lt;a href=&quot;#源码获取&quot; class=&quot;headerlink&quot; title=&quot;源码获取&quot;&gt;&lt;/a&gt;源码获取&lt;/h1&gt;&lt;p&gt;git clone &lt;a href=&quot;https://github.com/mysql/mysql-server&quot;
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="源码" scheme="http://idber.github.io/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的三种排序算法</title>
    <link href="http://idber.github.io/2019/04/28-MySQL%E7%9A%84%E4%B8%89%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.html"/>
    <id>http://idber.github.io/2019/04/28-MySQL的三种排序算法.html</id>
    <published>2019-04-28T02:01:56.000Z</published>
    <updated>2020-04-11T03:08:04.427Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;MySQL内部实现排序主要有3种方式，常规排序，优化排序和优先队列排序，主要涉及3种排序算法：快速排序、归并排序和堆排序。&lt;/p&gt;
&lt;p&gt;关于排序算法，Youtube上有套有意思的3D机器人演示视频命令，方便理解。&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=aXXWXz5rF64&amp;amp;index=2&amp;amp;list=PL2aHrV9pFqNRS2b2XX2BvgQIPKh72xREP&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;via&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;快速排序&quot;&gt;&lt;a href=&quot;#快速排序&quot; class=&quot;headerlink&quot; title=&quot;快速排序&quot;&gt;&lt;/a&gt;快速排序&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1940317-6d01faf07a21e730.gif?imageMogr2/auto-orient/strip&quot; alt=&quot;快速排序动画&quot;&gt;&lt;br&gt;快速排序视频动画，56秒开始，前面是冒泡法排序&lt;/p&gt;
&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=50732977&amp;bvid=BV114411b7qE&amp;cid=88823395&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt;

&lt;p&gt;快速排序（英语：Quicksort），又称划分交换排序（partition-exchange sort），简称快排，一种排序算法，最早由东尼·霍尔提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。&lt;/p&gt;
&lt;p&gt;快速排序是对冒泡排序的一种改进。在区间中随机挑选一个元素作基准，将小于基准的元素放在基准之前，大于基准的元素放在基准之后，再分别对小数区与大数区进行排序。&lt;/p&gt;
&lt;p&gt;快速排序使用分治法（Divide and conquer， 在计算机科学中，分治法是建基于多项分支递归的一种很重要的算法范式。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。）策略来把一个序列（list）分为较小和较大的2个子序列，然后递归地排序两个子序列。&lt;/p&gt;
&lt;p&gt;步骤为：&lt;br&gt;挑选基准值：从数列中挑出一个元素，称为“基准”（pivot），&lt;br&gt;分割：重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（与基准值相等的数可以到任何一边）。在这个分割结束之后，对基准值的排序就已经完成，&lt;br&gt;递归排序子序列：递归地将小于基准值元素的子序列和大于基准值元素的子序列排序。&lt;br&gt;递归到最底部的判断条件是数列的大小是零或一，此时该数列显然已经有序。&lt;/p&gt;
&lt;p&gt;由于基准是随机的，所以快速排序是不稳定排序。&lt;/p&gt;
&lt;h1 id=&quot;归并排序&quot;&gt;&lt;a href=&quot;#归并排序&quot; class=&quot;headerlink&quot; title=&quot;归并排序&quot;&gt;&lt;/a&gt;归并排序&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://bucket-1257126549.cos.ap-guangzhou.myqcloud.com/20181120110141.gif&quot; alt=&quot;归并排序动画&quot;&gt;&lt;/p&gt;
&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=50490785&amp;bvid=BV1w4411h7yq&amp;cid=88817956&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt;

&lt;p&gt;归并排序（英语：Merge sort，或mergesort），是创建在归并操作上的一种有效的排序算法。1945年由约翰·冯·诺伊曼首次提出。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。&lt;br&gt;把数据分为两段，从两段中逐个选最小的元素移入新数据段的末尾。&lt;br&gt;可从上到下或从下到上进行。&lt;/p&gt;
&lt;p&gt;归并操作&lt;br&gt;归并操作（merge），也叫归并算法，指的是将两个已经排序的序列合并成一个序列的操作。归并排序算法依赖归并操作。&lt;/p&gt;
&lt;p&gt;步骤为：&lt;br&gt;申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列&lt;br&gt;设定两个指针，最初位置分别为两个已经排序序列的起始位置&lt;br&gt;比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置&lt;br&gt;重复步骤3直到某一指针到达序列尾&lt;br&gt;将另一序列剩下的所有元素直接复制到合并序列尾&lt;/p&gt;
&lt;h1 id=&quot;堆排序&quot;&gt;&lt;a href=&quot;#堆排序&quot; class=&quot;headerlink&quot; title=&quot;堆排序&quot;&gt;&lt;/a&gt;堆排序&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1940317-64e671a84ec27769.gif?imageMogr2/auto-orient/strip&quot; alt=&quot;堆排序动画&quot;&gt;&lt;br&gt;堆排序（英语：Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于（或者大于）它的父节点。&lt;br&gt;从堆顶把根卸出来放在有序区之前，再恢复堆。&lt;/p&gt;
&lt;p&gt;若以升序排序说明，把数组转换成最大堆积(Max-Heap Heap)，这是一种满足最大堆积性质(Max-Heap Property)的二叉树：对于除了根之外的每个节点i, A[parent(i)] ≥ A[i]。&lt;/p&gt;
&lt;p&gt;重复从最大堆积取出数值最大的结点(把根结点和最后一个结点交换，把交换后的最后一个结点移出堆)，并让残余的堆积维持最大堆积性质。&lt;/p&gt;
&lt;p&gt;堆的操作&lt;br&gt;在堆的数据结构中，堆中的最大值总是位于根节点（在优先队列中使用堆的话堆中的最小值位于根节点）。堆中定义以下几种操作：&lt;br&gt;最大堆调整（Max Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点&lt;br&gt;创建最大堆（Build Max Heap）：将堆中的所有数据重新排序&lt;br&gt;堆排序（HeapSort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算&lt;/p&gt;
&lt;h1 id=&quot;MySQL的排序&quot;&gt;&lt;a href=&quot;#MySQL的排序&quot; class=&quot;headerlink&quot; title=&quot;MySQL的排序&quot;&gt;&lt;/a&gt;MySQL的排序&lt;/h1&gt;&lt;p&gt;a.常规排序&lt;br&gt;(1).从表t1中获取满足WHERE条件的记录&lt;br&gt;(2).对于每条记录，将记录的主键+排序键(id,col2)取出放入sort buffer&lt;br&gt;(3).如果sort buffer可以存放所有满足条件的(id,col2)对，则进行排序；否则sort buffer满后，进行排序并固化到临时文件中。(排序算法采用的是快速排序算法)&lt;br&gt;(4).若排序中产生了临时文件，需要利用归并排序算法，保证临时文件中记录是有序的&lt;br&gt;(5).循环执行上述过程，直到所有满足条件的记录全部参与排序&lt;br&gt;(6).扫描排好序的(id,col2)对，并利用id去捞取SELECT需要返回的列(col1,col2,col3)&lt;br&gt;(7).将获取的结果集返回给用户。&lt;br&gt;      从上述流程来看，是否使用文件排序主要看sort buffer是否能容下需要排序的(id,col2)对，这个buffer的大小由sort_buffer_size参数控制。此外一次排序需要两次IO，一次是捞(id,col2),第二次是捞(col1,col2,col3)，由于返回的结果集是按col2排序，因此id是乱序的，通过乱序的id去捞(col1,col2,col3)时会产生大量的随机IO。对于第二次MySQL本身一个优化，即在捞之前首先将id排序，并放入缓冲区，这个缓存区大小由参数read_rnd_buffer_size控制，然后有序去捞记录，将随机IO转为顺序IO。&lt;/p&gt;
&lt;p&gt;b.优化排序&lt;br&gt;     常规排序方式除了排序本身，还需要额外两次IO。优化的排序方式相对于常规排序，减少了第二次IO。主要区别在于，放入sort buffer不是(id,col2),而是(col1,col2,col3)。由于sort buffer中包含了查询需要的所有字段，因此排序完成后可以直接返回，无需二次捞数据。这种方式的代价在于，同样大小的sort buffer，能存放的(col1,col2,col3)数目要小于(id,col2)，如果sort buffer不够大，可能导致需要写临时文件，造成额外的IO。当然MySQL提供了参数max_length_for_sort_data，只有当排序元组小于max_length_for_sort_data时，才能利用优化排序方式，否则只能用常规排序方式。&lt;/p&gt;
&lt;p&gt;c.优先队列排序&lt;br&gt;     为了得到最终的排序结果，无论怎样，我们都需要将所有满足条件的记录进行排序才能返回。那么相对于优化排序方式，是否还有优化空间呢？5.6版本针对Order by limit M，N语句，在空间层面做了优化，加入了一种新的排序方式–优先队列，这种方式采用堆排序实现。堆排序算法特征正好可以解limit M，N 这类排序的问题，虽然仍然需要所有元素参与排序，但是只需要M+N个元组的sort buffer空间即可，对于M，N很小的场景，基本不会因为sort buffer不够而导致需要临时文件进行归并排序的问题。对于升序，采用大顶堆，最终堆中的元素组成了最小的N个元素，对于降序，采用小顶堆，最终堆中的元素组成了最大的N的元素。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;MySQL内部实现排序主要有3种方式，常规排序，优化排序和优先队列排序，主要涉及3种排序算法：快速排序、归并排序和堆排序。&lt;/p&gt;
&lt;p&gt;关于排序算法，Youtube上有套有意思的3D机器人演示视频命令，方便理解。&lt;br&gt;&lt;a href=&quot;https://www.
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="排序" scheme="http://idber.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="优化，算法" scheme="http://idber.github.io/tags/%E4%BC%98%E5%8C%96%EF%BC%8C%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Purge死锁</title>
    <link href="http://idber.github.io/2018/10/01-Purge%E6%AD%BB%E9%94%81.html"/>
    <id>http://idber.github.io/2018/10/01-Purge死锁.html</id>
    <published>2018-09-30T22:01:56.000Z</published>
    <updated>2019-04-22T01:41:16.932Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;h1 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h1&gt;&lt;p&gt;场景：业务批量删除，然后插入操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select @@tx_isolation;
+----------------+
| @@tx_isolation |
+----------------+
| READ-COMMITTED |
+----------------+
1 row in set, 1 warning (0.00 sec)

set global innodb_status_output_locks=1;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启用后，InnoDB锁定监视器会打印有关SHOW ENGINE INNODB STATUS输出锁定的附加信息&lt;/p&gt;
&lt;p&gt;为了演示繁忙的场景，使用debug版本启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/home/mysql/mysql/bin/mysqld-debug --basedir=/home/mysql/mysql --datadir=/home/mysql/data

set global innodb_purge_stop_now=1;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;show这个变量􏰀,结果还是off,这个不用管,purge线程已􏰁停止了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table test_purge(a int auto_increment primary key, b int , unique key(b));

insert into test_purge(b) values(10),(20),(30),(40),(50),(60);

select * from test_purge;
+---+------+
| a | b    |
+---+------+
| 1 |   10 |
| 2 |   20 |
| 3 |   30 |
| 4 |   40 |
| 5 |   50 |
| 6 |   60 |
+---+------+
6 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;加锁过程&quot;&gt;&lt;a href=&quot;#加锁过程&quot; class=&quot;headerlink&quot; title=&quot;加锁过程&quot;&gt;&lt;/a&gt;加锁过程&lt;/h1&gt;&lt;p&gt;终端会话1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;delete from test_purge where b=20;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;终端会话2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from test_purge;
beign;
insert into test_purge(b) values(20);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;终端会话3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pager less


show engine innodb status\G

---TRANSACTION 3342, ACTIVE 22 sec
3 lock struct(s), heap size 1160, 3 row lock(s), undo log entries 1
MySQL thread id 4, OS thread handle 139843750467328, query id 11 localhost root
TABLE LOCK table `guo_test`.`test_purge` trx id 3342 lock mode IX
RECORD LOCKS space id 28 page no 4 n bits 72 index b of table `guo_test`.`test_purge` trx id 3342 lock mode S
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 80000014; asc     ;;
 1: len 4; hex 80000002; asc     ;;

-- heap no=3表示是第二个插入的记录20
-- 且info bits为32,表示记录被标记删除了
0: len 4; hex 80000014; asc ;; -- 记录为20
1: len 4; hex 80000002; asc ;; -- 对应的主键为2


Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0
 0: len 4; hex 8000001e; asc     ;;
 1: len 4; hex 80000003; asc     ;;
-- heap no=4表示的是20的下一个记录30
-- 且该记录上也有S lock
RECORD LOCKS space id 28 page no 4 n bits 72 index b of table `guo_test`.`test_purge` trx id 3342 lock mode S locks gap before rec
Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 #heap no=6为新插入的记录20,从隐式锁提升为显示锁
 0: len 4; hex 80000014; asc     ;;
 1: len 4; hex 80000005; asc     ;;
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;因为是唯一索引,需要做唯一性检查,从老的记录 20&lt;em&gt; 开始检查(第一个小于等于自己的值),则此时 20&lt;/em&gt; 上要加上一把 S lock ,然后往下检查到第一个不相等的记录,即 记录30 ,然后退出,但是这个 记录30 也要 加上S lock&lt;/li&gt;
&lt;li&gt;在插入新的记录20的时候,发现下一条记录30上有锁,则自己插入的时的隐式锁提升为显示锁(见插入步骤)&lt;/li&gt;
&lt;li&gt;目前锁住的范围是 (10,20], (20,30]&lt;/li&gt;
&lt;li&gt;新插入的记录20本身是一把 S-Gap Lock (前面20*的有S lock了,由于是唯一索引,本身其实就不需要有记录锁了,有GAP就够了)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以25，15都无法插入，都在锁定区间&lt;br&gt;会话3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@guo_test 01:48:14&amp;gt;insert into test_purge(b) values(25);
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
root@guo_test 01:48:23&amp;gt;insert into test_purge(b) values(15);
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;Purge死锁演示&quot;&gt;&lt;a href=&quot;#Purge死锁演示&quot; class=&quot;headerlink&quot; title=&quot;Purge死锁演示&quot;&gt;&lt;/a&gt;Purge死锁演示&lt;/h1&gt;&lt;p&gt;删除50，20前面已经删除&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;delete from test_purge where b=50;
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;T1&lt;/th&gt;
&lt;th&gt;T2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;begin;&lt;/td&gt;
&lt;td&gt;begin;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;insert into test_purge(b) values(25);&lt;/td&gt;
&lt;td&gt;insert into test_purge(b) values(55);&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;insert into test_purge(b) values(50);&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;insert into test_purge(b) values(20);&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Deadlock found..&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;insert into test_purge(b) values(50);Query OK, 1 row affected (2.32 sec)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;show engine innodb status\G&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LATEST DETECTED DEADLOCK
------------------------
2018-09-18 12:25:41 0x7ff339aca700
*** (1) TRANSACTION:
TRANSACTION 6692, ACTIVE 53 sec inserting
mysql tables in use 1, locked 1
LOCK WAIT 4 lock struct(s), heap size 1160, 4 row lock(s), undo log entries 2
MySQL thread id 4, OS thread handle 140682621667072, query id 27 localhost root update
insert into test_purge(b) values(50)
*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 35 page no 4 n bits 80 index b of table `guo_test`.`test_purge` trx id 6692 lock mode S waiting
Record lock, heap no 9 PHYSICAL RECORD: n_fields 2; compact format; info bits 0
 0: len 4; hex 80000037; asc    7;;     #等待55的S锁
 1: len 4; hex 80000008; asc     ;;

*** (2) TRANSACTION:
TRANSACTION 6693, ACTIVE 28 sec inserting, thread declared inside InnoDB 5000
mysql tables in use 1, locked 1
4 lock struct(s), heap size 1160, 4 row lock(s), undo log entries 2
MySQL thread id 5, OS thread handle 140682621396736, query id 28 localhost root update
insert into test_purge(b) values(20)
*** (2) HOLDS THE LOCK(S):
RECORD LOCKS space id 35 page no 4 n bits 80 index b of table `guo_test`.`test_purge` trx id 6693 lock_mode X locks rec but not gap
Record lock, heap no 9 PHYSICAL RECORD: n_fields 2; compact format; info bits 0
 0: len 4; hex 80000037; asc    7;;      #持有55的S锁
 1: len 4; hex 80000008; asc     ;;

*** (2) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 35 page no 4 n bits 80 index b of table `guo_test`.`test_purge` trx id 6693 lock mode S waiting
Record lock, heap no 8 PHYSICAL RECORD: n_fields 2; compact format; info bits 0
 0: len 4; hex 80000019; asc     ;;      #等待25的S锁
 1: len 4; hex 80000007; asc     ;;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;该问题的场景&quot;&gt;&lt;a href=&quot;#该问题的场景&quot; class=&quot;headerlink&quot; title=&quot;该问题的场景&quot;&gt;&lt;/a&gt;该问题的场景&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;使用了唯一索引(主要原因)&lt;/li&gt;
&lt;li&gt;大量delete数据后,又立即插入了数据&lt;/li&gt;
&lt;li&gt;插入的数据和部分删除的数据的唯一索引一样,且purge还没有来得及回收删除的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;解决办法&quot;&gt;&lt;a href=&quot;#解决办法&quot; class=&quot;headerlink&quot; title=&quot;解决办法&quot;&gt;&lt;/a&gt;解决办法&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;delete后等待较长时间后(增大purge线程数,等Purge回收),再插入新数据 (不推荐) &lt;/li&gt;
&lt;li&gt;使用普通索引&lt;/li&gt;
&lt;li&gt;仍然使用唯一索引,但是插入前要对唯一索引进行分线程排序 (只会有等待,不会有死锁)&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h1 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h1&gt;&lt;p&gt;场景：业务批量删除，然后插入操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select @@tx_isolation;
+-
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="死锁" scheme="http://idber.github.io/tags/%E6%AD%BB%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>Percona Xtrabackup 2.4 恢复指定表</title>
    <link href="http://idber.github.io/2018/09/09-Percona%20Xtrabackup%202.4%20%E6%81%A2%E5%A4%8D%E6%8C%87%E5%AE%9A%E8%A1%A8.html"/>
    <id>http://idber.github.io/2018/09/09-Percona Xtrabackup 2.4 恢复指定表.html</id>
    <published>2018-09-08T22:01:56.000Z</published>
    <updated>2019-04-22T01:41:16.932Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;在5.6之前的服务版本，在不同的MySQL服务中通过复制表的文件来拷贝表是不可能的，即使启用了innodb_file_per_table。然而，通过Percona XtraBackup，可以从任意的InnoDB数据库中导出指定的表，并将它们导入到使用XtraDB的Percona服务中或MySQL 5.6。这只对.ibd文件有效。 &lt;/p&gt;
&lt;p&gt;创建测试表 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `export_test` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `a` varchar(60) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3   ROW_FORMAT=DYNAMIC  DEFAULT CHARSET=utf8

insert into `test`.`export_test` ( `a`) values ( &amp;apos;aaa&amp;apos;);
insert into `test`.`export_test` ( `a`) values ( &amp;apos;ddd&amp;apos;);
insert into `test`.`export_test` ( `a`) values ( &amp;apos;ccc&amp;apos;);
insert into `test`.`export_test` ( `a`) values ( &amp;apos;dddccc&amp;apos;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;确认innodb_file_per_table是否开启&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &amp;apos;innodb_file_per_table&amp;apos;; 
+-----------------------+-------+ 
| Variable_name         | Value | 
+-----------------------+-------+ 
| innodb_file_per_table | ON    | 
+-----------------------+-------+ 
1 row in set (0.00 sec) 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;确认行格式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &amp;apos;%format%&amp;apos;;
+---------------------------+-------------------+
| Variable_name             | Value             |
+---------------------------+-------------------+
| binlog_format             | ROW               |
| date_format               | %Y-%m-%d          |
| datetime_format           | %Y-%m-%d %H:%i:%s |
| default_week_format       | 0                 |
| innodb_default_row_format | dynamic           |
| innodb_file_format        | Barracuda         |
| innodb_file_format_check  | ON                |
| innodb_file_format_max    | Barracuda         |
| time_format               | %H:%i:%s          |
+---------------------------+-------------------+
9 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行备份 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innobackupex --defaults-file=/etc/my.cnf --user=bkuser --password=xxxx  --socket=/tmp/mysql.sock ~/backup/fullbackup/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;导出的表必须是以 innodb_file_per_table 格式创建，在备份目录中以.bd文件格式存在。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find . -name export_test.*
./guo_test/export_test.ibd
./guo_test/export_test.frm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当准备备份的时候，增加xtrabackup –export参数到命令中。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innobackupex --user=root --password=root --no-timestamp --apply-log --export ./
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在目标目录下，可以看到.exp文件 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find . -name export_test.*
./guo_test/export_test.ibd
./guo_test/export_test.exp
./guo_test/export_test.cfg
./guo_test/export_test.frm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;.exp、.ibd、.cfg这三个文件用于数据库导入中&lt;br&gt;Percona官方对这三个文件的描述&lt;br&gt;After this, copy mytable.ibd and mytable.exp ( or mytable.cfg if importing to MySQL 5.6) files to database’s home, and import its tablespace:&lt;/p&gt;
&lt;p&gt;删除表 （如果表结构一致可以不用删除）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;drop table export_test; 
Query OK, 0 rows affected (1.45 sec) 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在目标MySQL服务器上，创建一张具有相同结构的空表。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `export_test` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `a` varchar(60) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3   ROW_FORMAT=DYNAMIC  DEFAULT CHARSET=utf8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;清除表空间&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE export_test DISCARD  TABLESPACE;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;拷贝导出文件到数据目录中 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp -f  ~/export_test.* ./
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;更改文件权限为mysql &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chown -R mysql:mysql .  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;导入表空间&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE export_test IMPORT TABLESPACE;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;验证表中的数据 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select * from `test`.`export_test`;
+----+--------+
| id | a      |
+----+--------+
| 1  | aaa    |
| 2  | ddd    |
| 3  | ccc    |
| 4  | dddccc |
+----+--------+
4 rows in set (0.02 sec)

mysql&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常见错误&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;ERROR 1815 (HY000): Internal error: Cannot reset LSNs in table &amp;apos;&amp;quot;test&amp;quot;.&amp;quot;export_test&amp;quot;&amp;apos; : Tablespace not found 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看export文件权限、export文件是否都已经导入到数据库目录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;ERROR 1030 (HY000): Got error -1 from storage engine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查innodb_file_per_table是否开启&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;Error : Schema mismatch (Table flags don&amp;apos;t match, server table has 0x0 and the meta-data file has 0x1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查表ROW_FORMAT、innodb_file_format&lt;br&gt;以前支持COMPACT、REDUNDANT的innodb_file_format文件格式为Antelope，新的文件格式为Barracuda，新增格式Compressed、dynamic&lt;br&gt;    innodb_file_format&lt;br&gt;    Default Value (&amp;gt;= 5.7.7)    Barracuda&lt;br&gt;    Default Value (&amp;lt;= 5.7.6)    Antelope&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;在5.6之前的服务版本，在不同的MySQL服务中通过复制表的文件来拷贝表是不可能的，即使启用了innodb_file_per_table。然而，通过Percona XtraBackup，可以从任意的InnoDB数据库中导出指定的表，并将它们导入到使用XtraDB的
    
    </summary>
    
      <category term="MySQL" scheme="http://idber.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://idber.github.io/tags/MySQL/"/>
    
      <category term="备份恢复" scheme="http://idber.github.io/tags/%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"/>
    
  </entry>
  
</feed>
